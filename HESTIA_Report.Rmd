---
title: "HESTIA_Report"
author: "Oskar Nyberg"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# These libraries are used for analysis
   #install.packages("webchem")
   #install.packages("taxize")   # <- Installing the "taxize" library http://dx.doi.org/10.5281/zenodo.7097
   #install.packages("networkD3") <- For the Sankey flow chart visualization
   #install.packages("goeveg") # <- for simple coefficient of Variation calculation at summary of data
    library(rmarkdown)
    library(tidyverse)
    library(webchem)
    library(xlsx)
    library(readr)
    library(kableExtra)
    library(taxize)
    library(ggpubr)
    library(networkD3)
```
# HESTIA ecotoxicological database supplementary
\vspace{40mm}

Oskar Nyberg$^{1,\dagger}$, Reinout Heijungs$^{2}$, Patrik Henriksson$^{3,4,5}$

\vspace{20mm}
${1}$ Department of Ecology, Environment and Plant Sciences,  Svante Arrhenius väg 20 A, Stockholm University
${2}$ Leiden University
${3}$ Stockholm Resilience Center, XXX, Stockholm University
${4}$ WorldFish Center
${5}$ Beijer Institute

${\dagger}$ Corresponding author:[oskar.nyberg@su.se](mailto:oskar.nyberg@su.se)



\newpage

# HESTIA Database construction.
The starting point for constructing a database with ecotoxicological data to calculate characterization factors suited for the online life cycle assessment (LCA) application HESTIA ([http://HESTIA.earth](http://hestia.earth)) is the substance inventory acquired as the .csv file `Pesticide.AI`. This is a list of 16797 potentially harmful substances based on the United States Environmental Protection Agency's Substance Registry Services (USEPA SRS) inventory. (Probably). 

The first operation is to import this list of substances and select CAS registry numbers (CASRN) and substance names, as well as reformatting CASRN format from `CAS-XXXX-XX-X` to `XXXX-XX-X`. Then, we use the NCBI PubChem project to match CASRN and substance names to SMILES configuration with the intermediate step of aquiring PubChem substance IDs using the R package [Webchem](https://docs.ropensci.org/webchem/) [@Webchem_2020].

```{r}
# This step takes place in the `code/Translating_CAS_to_SMILES_via_PubChem.R`-file
# Output from this operation creates three files: a .csv doc "data/excel_references/CAS_CID_list_final.csv", a .txt file containing CASRN-SMILES matches: "data/excel_references/CAS_CID_list_final.txt", as well as five subsets from the previous .txt file named "data/excel_references/cas_smiles_list[XXXX-XXXXk].txt"
```

Based off of the CASRN-SMILES matches we take three actions: 1) query substance use info, to annotate use-types for each substance respectively `code/Pesticide_annotations.Rmd`, 2) query the OECD QSAR Toolbox [REF] for physicochemical properties for substances and subsequently read and wrangle data for a USEtox-friendly format `Physchem_read_wrangle_function`, and 3) query the OECD QSAR Toolbox [REF] for substances' aquatic ecotoxicological records. 
**Reading the physchem-data to enable analysis of WHY uncertainty ratios vary as they do**
```{r Physchem info, echo=FALSE}
# Physchem wrangle function
source("code/Physchem_read_wrangle_function.R")

Physchem_HESTIA <- Physchem_read_wrangle_function(read.csv("data/QSAR_Toolbox_physchem_data_2023-03-24_RAW.csv",header = T, sep = "\t", na.strings = "", fileEncoding = "UTF-16LE",  stringsAsFactors = FALSE))
```


In several steps of these filtering operations, physicochemical data is required, which is available for **`r nrow(Physchem_HESTIA)`** substances, code loaded from file ""../code/Physchem_read_wrangle_function.R"". This is imported at the here at the onset of data wrangling, because I need some of the physicochemical data and the pesticide annotations below (for pesticides, ACR annotations are 2.2, not standard 2, when converting EC50_acute -> EC50_chronic in USEtoc v2.1 according to USEtox manual!)

## Raw data wrangling
```{r reading TOX data}
# Reading in the data input ready for wrangling. "Pre-filtered" implying that the data has been 
# Dependency -> "data/raw_data_read_and_wrangle.R"
HESTIA_HC20_DB_raw <- read.csv("data/RAW_DB/HESTIA_HC20_DB_raw_toxdata.csv")
names_db <- HESTIA_HC20_DB_raw %>% distinct(Database) %>% pull(Database)
n_db1 <- nrow(HESTIA_HC20_DB_raw %>% filter(Database == "ECOTOX"))
n_db2 <- nrow(HESTIA_HC20_DB_raw %>% filter(Database == "Aquatic OASIS"))
n_db3 <- nrow(HESTIA_HC20_DB_raw %>% filter(Database == "Aquatic ECETOC"))
n_db4 <- nrow(HESTIA_HC20_DB_raw %>% filter(Database == "Aquatic Japan MoE"))
n_db5 <- nrow(HESTIA_HC20_DB_raw %>% filter(Database == "Food TOX Hazard EFSA"))
```

Importing, filtering and wrangling the ecotoxicological effect data from QSAR data output, including relevant metadata that can act as quality control. In this operation the OECD QSAR Toolbox output gets read in and a first step of harmonizing the data set. The files have different lengths and number of columns, which forces me to select a set of defined columns. Additionally, duplicates and completely empty records have been removed to have a neater data set to work with.
Available from the `r count(HESTIA_HC20_DB_raw %>% distinct(Database))` databases; `r names_db[1]`, `r names_db[2]`, `r names_db[3]`,`r names_db[4]`, and `r names_db[5]` with `r n_db1`, `r n_db2`, `r n_db3`, `r n_db4`, and `r n_db5` records respectively.

However, anomalies were discovered when visualizing the finished data that are easily fixed at the onset of wrangling. After inspecting source material, it is clear that most of these are incorrect entries into the ECOTOX database. Also, fixing the publication year of source material by merging two columns since different databases have different names for publication year. **Push to export a table of these?**
```{r Adjusting misrepresented data}
# Fixing a few data points that, after original source inspection, turns out to be incorrectly entered into the database and cause large spread of data. 
HESTIA_HC20_DB <- HESTIA_HC20_DB_raw %>% 
  mutate(
    Value.MeanValue = gsub(pattern = ",", ".", Value.MeanValue), # replacing excel-format commas for dots.
    Value.MeanValue = as.numeric(Value.MeanValue),
    # Value entered as 10^+4.46... but should be exponented negatively: 10^-4.46...
    Value.MeanValue = case_when(grepl("Structural Alerts", Title) & CAS.Number == "122-66-7" ~  2.238721E-05,
                          TRUE ~ Value.MeanValue), 
    # Entered as incorrect toxicity unit
    Value.Unit = case_when(CAS.Number == "21145-77-7" & Author == "Artola-Garicano,E., T.L. Sinnige, I. Van Holsteijn, W.H.J. Vaes, and J.L.M. Hermens" ~ "µg/L",
                          TRUE ~ Value.Unit), 
    # Entered as incorrect toxicity unit
    Value.Unit = case_when(grepl("The Acute and Chronic Toxicity of Ten Chlorinated Organic Compounds to the American Flagfish", Title) ~ "µg/L",
                          TRUE ~ Value.Unit), 
    # Entered as incorrect toxicity unit (mg/L instead of µM)
    Value.Unit = case_when(grepl("The Influence of Solvents on the Acute Toxicity of some Lipophilic Chemicals to Aquatic Invertebrates", Title) ~ "µM",
                          TRUE ~ Value.Unit), 
    # Entered as incorrect toxicity unit (mg/L instead of µM/L)
    Value.Unit = case_when(grepl("Comparative Acute Toxicity of the First 50 Multicentre Evaluation of In Vitro Cytotoxicity Chemicals to Aquatic Non-vertebrates", Title) ~ "µM/L",
                          TRUE ~ Value.Unit), 
    # Data entered as x M effect conc. But should be entered as 1/10^x M. 
    Value.MeanValue = case_when(Author == "Wakabayashi,K., G. Sandmann, H. Ohta, and P. Boger" ~ 1/(10^Value.MeanValue),
                          TRUE ~ Value.MeanValue), 
    # Value incorrectly entered with 3 extra 0's
    Value.MeanValue = case_when(grepl("Effects of Age and Coion (K+ and Na+) on the Toxicity", Title) & Value.MeanValue >10000 ~ Value.MeanValue/1000, 
                          TRUE ~ Value.MeanValue),
         CAS.Number = case_when(grepl("An aquatic toxicological evaluation of fenthion in the context of finch control in South Africa", Title) ~ "55-38-9",
                                TRUE ~ CAS.Number),
    # making all these data as character for coding flow purposes below.
    Value.MeanValue = as.character(Value.MeanValue) 
         ) %>% 
# Merging columns of publication year
    mutate(Year = case_when(is.na(Year) ~ Publication.year,
                            TRUE ~ Year)) %>% 
    select(-Publication.year)  # Removing redundant column
```

### Which endpoints to include.
Saouter et al.(2022) defined 6 different conversion coefficients for chronic/acute EC50 -> chronic EC10 etc.
Leo Posthuma used several more, all ECx (1-20), records with the endpoints NOEC, LOEC, maximum acceptable toxicant concentration, EC0, EC5, EC10, and EC20 are marked as “chronic NOEC”, records with (EC) or (LC) endpoint ranging from 30 to 70% are marked as “acute EC50”
Acute/chronic definitions are available in Posthuma et al., 2019 (Table 1) and Aurisano et al., 2019 for algae, bacteria, unicellular animals, crustaceans, fish, molluscs/worms/etc.  

Harmonization and aggregation of endpoints  
[$Aurisano et al., 2019, p. 2570$]  
EC0, EL0, IC0, LC0, NOAEC, NOEC, NOEbC, NOErC, NOEL grouped into NOEC;  EC10, IC10, LC10, LOEC grouped into EC10eq;  EC50, EbC50, EbL50, ErC50, ErL50, IC50, LC50 grouped into EC50.  
“We combined LOEC and EC10 for deriving extrapolation factors based on high uncertainties in the low range of species sensitivity distributions, rendering it difficult to treat LOEC and EC10 as separate metrics in statistical analyses (Iwasaki et al. 2015; King et al. 2017).” [Aurisano et al., 2019, p. 2571]

```{r Endpoint selection}
# Dependency on the manually curated excel file where endpoints were selected and harmonized endpoint was given to each record respectively 
Harmonized_endpoints_table <- knitr::kable(
  read.csv("data/excel_references/Endpoints_selector.csv", sep = ";") %>% 
    filter(
      !Group == "N",
      !is.na(Group)) %>% 
    arrange(Group),
  caption = "Table of effect data endpoints included in the construction of the HESTIA toxicological database",
  col.names = c("Endpoint", "n", "Harmonized Endpoint(*q*)")
)

```
`r Harmonized_endpoints_table`



```{r test_qualifier}

Qualifier_summary_table <- knitr::kable(
  read.csv("data/excel_references/summary table for value.qualifiers.csv"),
  col.names = c("Qualifier type  ", "Count across all  ", "Count min qualifier  ", "Count max qualifier"), 
  align = c("l", "c", "c", "c")
  
  )
    
```
### Values reported in range
Effect concentration qualifiers 
Based on similar work by Saouter et al., 2019, in cases where no mean value is reported, the following rules will be applied:
“A large majority of the results have a numeric value in the low range with a qualifier =, ca., >=, or >. In contrast, only a few tests have their results expressed in the higher ranges (5862 test results). The following selections were made to maximize the use of available data:   
1. When there is a lower range value with the descriptors ‘>=, ca., or empty’, the lowest value is selected. If, within this group, a test has also a higher value, this higher value is ignored.  
2. All lower range values described as ‘>’ are ignored (n = 39602), unless the higher value is described as ‘=<’ (n= 80 observations). In case of NOEC > than, the value was kept since it is still representing a concentration with no observed effect.  
3. All higher values described as ‘< than’ are ignored, unless the lower range value is described as ‘>=’. Then the lower value is used.  
4. When a lower range value is missing (0 or blank) and a higher value is available described as ‘<=’, the higher value is used.  
5. When a lower value is described as >= and the higher value is described as <=, the lowest value is used.  
6. Values expressed as ‘<’ are excluded (4397 test results).” [Saouter et al., 2018, p. 47]  
The counts of effect concentration qualifier annotations 
`r Qualifier_summary_table`

### Test media (Freshwater & culture media filter)
Assuming tests without defined media type is "freshwater". Especially considering the majority of organisms are Daphnia magna, Pseudokirchneriella subcapitata, Pimephales promelas and Oryzias latipes (after inspection), just as Saouter 2018.

```{r test_medium}
# Summary table of test media
test_media_sum <- knitr::kable(
  HESTIA_HC20_DB_raw %>% 
    mutate(
      Media.type = gsub(" ", "", Media.type),
      Media.type = coalesce(
        Media.type, Water.type)
    ) %>% 
    group_by(Media.type) %>% 
    summarise(n = n()
    )
  )
```
`r test_media_sum`

### Effect Criterion selection 
Posthuma et al., 2019, selected few effect criterion where: 
"... records with the endpoints NOEC, lowest-observed-effect concentration, maximum acceptable toxicant concentration, EC0, EC5, EC10, and EC20 are marked as “chronic NOEC” when they have an appropriate taxon-dependent test duration (see Table 1) and population-relevant effect criterion (e.g., reproduction, growth, population growth, and development, next to mortality and immobility); and records with a sublethal (EC) or lethal endpoint ranging from 30 to 70% are marked as “acute EC50” when they have an appropriate taxon-dependent test duration (see Table 1) and effect criterion (e.g., mortality and immobility).
However, Posthuma et al. also clustered NOEC, LOEC, EC 0-20 into one "Chronic NOEC"-category and all EC 30-70 into one Acute EC50 category. 

We decide to select endpoint criterions based on expert consultation with dr. Andreu Rico
```{r effect_criterions}
summary_effect_crit_rawinput <- HESTIA_HC20_DB_raw %>% 
  group_by(Effect) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n))

summary_effect_crit_filtered <- knitr::kable(read.csv("data/excel_references/summary_table_effect_crit.csv"))
```
`r summary_effect_crit_filtered`

### Defining Acute/chronic conditions 
Operation based on taxonomic group
First step is to harmonize test durations and test concentration units and transform test concentrations into mg/L measurements. This is performed according to table
step 4: Filter out data that is not convertable into correct time units or concentration formats.

Step 5: Define Acute or Chronic test conditions:

effect concentration conversions needs a revision:
 - #For toxic endpoints, are milligrams per liter (mg / L) equivalent to parts per million (ppm)?
The endpoint concentrations for regulated toxic substances under the risk management program rule (40 CFR Part 68 Appendix A) are listed in units of milligrams per liter (mg/L).  Is this equivalent to parts per million (ppm)?
No, mg/L is not always equivalent to ppm.  Whereas ppm is a volume-to-volume or mass-to-mass ratio, mg/l is a mass-to-volume relationship.  To convert from units of mg/L to ppm, use the following equation.  Endpoint (ppm) = [Endpoint (mg/L) x 1000 x 24.5] / [Molecular Weight]  EPA has included the RMP toxic endpoints in both ppm and mg/L in Appendix B of the Risk Management Program Guidance for Offsite Consequence Analysis (EPA550-B-99-009, April, 1999).#

Hence, to convert ppm or ppb to mg/L, I need to redo the conversions. 
Endpoint (ppm) = [Endpoint (mg/L) x 1000 x 24.5] / [Molecular Weight] -->
Endpoint (ppm) x Molecular Weight / 1000 x 24.5 = Endpoint (mg/L) 





### EC10eq conversions

```{r EC10eq conversions}
EC10eq_table_names <- c(
  "Harmonized endpoint (q)",
  "Acute or chronic exposure (a)",
  "Taxonomy group (t)",
  "extrapolation factor (g)",
  "High CI (95%)(h)",
  "Low CI (95%)(l)"
)

EC10eq_conversion_table <- knitr::kable(data.frame(
  q = c(rep("EC50", 8), rep("EC10", 8), rep("NOEC", 8)), # Endpoints (q)
  a = c(rep(c(rep("Acute", 4), rep("Chronic", 4)), 3)), # Acute or chronic exposure (a)
  t = c(rep(c("Fish", "Crustacean", "Algae", "Others"), 6)), # Taxonomy group (t)
  g = as.numeric(c(7.44, 3.38, 4, 4, 1.55, 1.94, 2.24, 2, rep(1, 8), 3.97, 1.55, 1.8, 1.8, 0.6, 0.95, 0.44, 0.6)), # extrapolation factor (g)
  h = as.numeric(c(18.95, 5.34, 6.1, 6.1, 3.66, 2.41, 2.65, 2.5, rep(1, 8), 17.39, 2.64, 2.7, 2.7, 0.7, 1.16, 0.49, 0.7)), # High CI (95%) extrapolation factor (h)
  l = as.numeric(c(2.92, 2.14, 2.6, 2.6, 0.67,  1.56, 1.9, 1.8, rep(1, 8), 0.9, 0.91, 1, 1, 0.4, 0.77, 0.39, 0.4)) # Low CI (95%) extrapolation factor (l)  
  ),
  col.names = EC10eq_table_names
)

```



With endpoints harmonized according to EC10eq conversions
`r EC10eq_conversion_table`


### Summarising the chemical properties work
How many different types of substances can be ascribed a certain use-property?
By looking in several data repositories I have collected data on use properties for substances. These are summarized in table below. Process documentation is needed to be summarized as well.

```{r}
propery_summary <- knitr::kable(data.frame(
  read.csv("results/HESTIA_chem_prop_list_full.csv") %>% 
  count(Group, sort = T)
))
```

`r propery_summary`


### Summarizing the HC20 Characterization factor dataset

```{r}
HC20_DB_summary <- knitr::kable(data.frame(
read.csv("results/HESTIA_HC20_dataset.csv") %>% 
  count(!is.na(HC20), sort = T)
))

# How many substances in the input DB
# nrow(read.csv("data/RAW_DB/HESTIA_HC20_DB_raw_toxdata.csv") %>%
#   distinct(CAS.Number))


# Output My database construction
# Treated - Ready-to-characterize data
treated_DB_endpoints <- knitr::kable(data.frame(
  read.csv("results/HESTIA_EC10eq_pure_DB.csv") %>% 
  count(Endpoint_conv, AcuteChronic)
))

# read.csv("results/HESTIA_EC10eq_pure_DB.csv") %>% 
#   count(Endpoint_conv, AcuteChronic) %>% 
#   #group_by(n) %>% 
#   summarise(n = sum(n))

```

`r treated_DB_endpoints`