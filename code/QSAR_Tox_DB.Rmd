---
title: "QSAR_Tox_DB"
author: "Oskar Nyberg"
date: "`r Sys.Date()`"
output: html_document
---
# Dir & Libraries

```{r setup}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, verbose = TRUE)
# These libraries are used for analysis
   #install.packages("webchem")
   #install.packages("taxize")   # <- Installing the "taxize" library http://dx.doi.org/10.5281/zenodo.7097
   #install.packages("networkD3") <- For the Sankey flow chart visualization
   #install.packages("goeveg") # <- for simple coefficient of Variation calculation at summary of data
    library(rmarkdown)
    library(xlsx)
    library(tidyverse)
    library(readr)
    library(kableExtra)
    library(webchem)
    library(taxize)
```

QSAR Estimations generated for the HESTIA database 

QSAR models are mathematical models that correlate the structure of a chemical compound with its toxicity or other biological activity. These models can be used to predict the toxicity of new chemicals that have not yet been tested in vivo or in vitro, and they can also be used to screen large numbers of chemicals for potential toxicity. To build a QSAR model, a large dataset of chemicals with known toxicity data is needed. This dataset is usually divided into a training set and a validation set. The training set is used to build the model, while the validation set is used to test the model's predictive power. The structure of each chemical in the dataset is described by a set of molecular descriptors, which are numerical values that reflect various physicochemical properties of the molecule, such as its size, shape, charge, and polarity. These descriptors can be calculated using computational chemistry software. The next step is to select a statistical or machine learning algorithm to build the QSAR model. There are many different algorithms that can be used, such as multiple linear regression, support vector machines, random forests, and neural networks. The algorithm is trained using the molecular descriptors of the chemicals in the training set, along with their corresponding toxicity data. The resulting model can then be used to predict the toxicity of new chemicals based on their molecular descriptors. It's important to note that QSAR models have limitations and should not be relied upon as the sole method for assessing chemical toxicity. They are best used as a screening tool to identify chemicals that may require further testing. Additionally, QSAR models are only as good as the data they are based on, so it's important to ensure that the dataset used to build the model is comprehensive and representative of the chemicals being studied.

First step is to produce lists of SMILES-configurations to be used in VEGA
Quick output of all the SMILES configuration of all chemicals as a .txt list (for VEGA-QSARs)
Vega is bad at allocating RAM and needs shorter lists ~5000 chemicals each. so I am exporting 3 different lists of n ~5000 chemicals!
This output is generated in the first chunk below with files called "QSAR_SMILES_list[xk-xxk].txt"
First order is to annotate the CAS_SMILES_list with an indexing ID number, since the SMILES output from VEGA software will be in different format from the SMILES input. no idea why. 
so, first make an index column -> remove all NAs -> export subsets (3x lists). RUN data through VEGA software, then import results (rbind the 3x files) and merge back with the matrix containing CASRN, SMILES and index ID.

```{r VEGA_input_generator, eval = F}
#cas_smiles_list <- read.csv("../data/excel_references/Full_CAS_SMILES.csv")
CAS_SMILES_list <- read_tsv("../data/excel_references/CAS_CID_list_final.txt", col_names = F)
names(CAS_SMILES_list) <- c("CAS.Number", "SMILES")
CAS_SMILES_list_no_na <- CAS_SMILES_list %>% 
  filter(!is.na(SMILES))
write.table(CAS_SMILES_list_no_na[1:5000,2], "../data/excel_references/QSAR_SMILES_list[1-5k].txt", row.names = F, col.names = F, quote = F, sep = "\t")
write.table(CAS_SMILES_list_no_na[5001:10000,2], "../data/excel_references/QSAR_SMILES_list[5k-10k].txt", row.names = F, col.names = F, quote = F, sep = "\t")
write.table(CAS_SMILES_list_no_na[10001:nrow(CAS_SMILES_list_no_na),2], "../data/excel_references/QSAR_SMILES_list[10-15k].txt", row.names = F, col.names = F, quote = F, sep = "\t")
```

```{r}
# list of models used for QSAR estimations:
QSAR_model_list <- read.delim("../data/excel_references/QSAR_output/report_summary[1-5k].txt", sep = "\t", col.names = T, na.strings = c("[Error]-", "", "NA"))[1:19,]
QSAR_result_names <- names(read.delim("../data/excel_references/QSAR_output/report_summary[1-5k].txt", sep = "\t", skip = 21, na.strings = c("[Error]-", "", "NA")) %>% 
  # remove all predictions columns and keep the assessment columns
  select(!contains(c("prediction", "Classification", "SarPy", "DEMETRA"))))[-c(1:3)]


VEGA_QSARS <- cbind(
  CAS_SMILES_list_no_na, 
  bind_rows(
    read.delim("../data/excel_references/QSAR_output/report_summary[1-5k].txt", sep = "\t", skip = 21#, na.strings = c("[Error]-", "", "NA")
               ),
    read.delim("../data/excel_references/QSAR_output/report_summary[5k-10k].txt", sep = "\t", skip = 21#, na.strings = c("[Error]-", "", "NA")
               ),
    read.delim("../data/excel_references/QSAR_output/report_summary[10k-15k].txt", sep = "\t", skip = 21#, na.strings = c("[Error]-", "", "NA")
               ) %>% 
      mutate(Daphnia.Magna.LC50.48h..DEMETRA..prediction...log.mol.l.. = as.double(Daphnia.Magna.LC50.48h..DEMETRA..prediction...log.mol.l..)) # this col is read as "character" in only this document
    ) %>% 
  select(-c(No., tId)
  ) %>% 
  rename(SMILES_VEGA = SMILES)
  ) %>% 
  # remove all predictions columns and keep the assessment columns
  select(!contains(c("prediction", "Classification", "SarPy", "DEMETRA"))) %>%  
  # Transforming the assessment columns into numeric effect concentrations and keeping the quality parameter in separate column 
    separate(Fish.Chronic..NOEC..Toxicity.model..IRFMN..assessment, c("Fish_Chronic_NOEC_IRFMN_NOEC_mgL", "Fish_Chronic_IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>% 
    separate(Daphnia.Magna.Chronic..NOEC..Toxicity.model..IRFMN..assessment, c("D.magna_Chronic_NOEC_IRFMN_NOEC_mgL", "D.magna_Chronic_IRFMN_eval"), convert = TRUE, sep = (" mg/L "), extra = "merge") %>% 
    separate(Algae.Chronic..NOEC..Toxicity.model..IRFMN..assessment, c("Algae_Chronic_NOEC_IRFMN_NOEC_mgL", "Algae_Chronic_IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>% 
    separate(Fish.Acute..LC50..Toxicity.model..IRFMN..assessment, c("Fish_Acute_LC50_IRFMN_mgL", "Fish_Acute_IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Fish.Acute..LC50..Toxicity.model..NIC..assessment, c("Fish_Acute_LC50_NIC_mgL", "Fish_Acute_NIC_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Fish.Acute..LC50..Toxicity.model..KNN.Read.Across..assessment, c("Fish_Acute_LC50_KNN_mgL", "Fish_Acute_KNN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Fish.Acute..LC50..Toxicity.model..IRFMN.Combase..assessment, c("Fish_Acute_LC50_IRFMN.Combase_mgL", "Fish_Acute_IRFMN.Combase_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Fathead.Minnow.LC50.96h..EPA..assessment, c("Fathead_Minnow_Acute_LC50_EPA_mgL", "Fathead_Minnow_Acute_EPA_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Fathead.Minnow.LC50.model..KNN.IRFMN..assessment, c("Fathead_Minnow_Acute_LC50_KNN.IRFMN_mgL", "Fathead_Minnow_Acute_KNN.IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>% # ECOTOX 6.1.1. Short-term toxicity to fish
    separate(Guppy.LC50.model..KNN.IRFMN..assessment, c("Guppy_Acute_LC50_KNN.IRFMN_mgL", "Guppy_Acute_KNN.IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>% # ECOTOX 6.1.1. Short-term toxicity to fish
    separate(Daphnia.Magna.Acute..EC50..Toxicity.model..IRFMN..assessment, c("D.magna_Acute_EC50_IRFMN_mgL", "D.magna_Acute_IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Daphnia.Magna.LC50.48h..EPA..assessment, c("D.magna_Acute_LC50_EPA_mgL", "D.magna_Acute_EPA_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    #separate(Daphnia.Magna.LC50.48h..DEMETRA..assessment, c("D.magna_Acute_LC50_DEMETRA_mgL", "D.magna_Acute_DEMETRA_eval"), sep = (paste(c(" mg/L ", " mg/l"), collapse = "|")), convert = TRUE, extra = "merge") %>%
    separate(Daphnia.Magna.Acute..EC50..Toxicity.model..IRFMN.Combase..assessment, c("D.magna_Acute_EC50_IRFMN.Combase_mgL", "D.magna_Acute_IRFMN.Combase_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Algae.Acute..EC50..Toxicity.model..IRFMN..assessment, c("Algae_Acute_EC50_IRFMN_mgL", "Algae_Acute_IRFMN_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    separate(Algae.Acute..EC50..Toxicity.model..ProtoQSAR.Combase..assessment, c("Algae_Acute_EC50_ProtoQSAR.Combase_mgL", "Algae_Acute_ProtoQSAR.Combase_eval"), sep = (" mg/L "), convert = TRUE, extra = "merge") %>%
    # Assigning columns as numeric type
    mutate(
      across(contains("_mgL"), ~ as.numeric(.x)),
  # removing redundant text in quality parameter column
      across(contains("_eval"), ~ as.character(gsub("\\(", "", .x))),
      across(contains("_eval"), ~ as.character(gsub(" reliability)", "", .x))),
      across(contains("_eval"), ~ as.character(gsub(" value)", "", .x)))
      ) 


VEGA_EC10 <- VEGA_QSARS %>%
  mutate(
    # Tranforming data reported as 0 mg/L which further down creates infinite avlogHC50 values. these are obviously misrepresenting the toxicity.
    across(contains("_mgL"), ~ na_if(.x, 0)),
    # Acute EC50 to Chronic EC10eq conversion
    across(contains("Acute_EC50"), ~ .x/2), 
    # Acute LC50 to Chronic EC10eq conversion
    across(contains("Acute_LC50"), ~ .x/2), 
    # Chronic NOEC to Chronic EC10eq conversion
    across(contains("Chronic_NOEC"), ~ .x/0.6), 
    ) %>%  
  # Changing names after the Chronic EC10eq
  setNames(gsub(paste(c("Acute_EC50", "Acute_LC50", "Chronic_NOEC"), collapse = "|"), "Chronic_EC10eq", names(.))) #%>%

VEGA_summary <- gather(VEGA_EC10 %>% 
         select(contains("_eval")), key = "QSAR_model", value) %>%
  count(QSAR_model, value) %>%
  spread(value, n) %>% 
  rename(ERROR = 6) %>% 
  select(QSAR_model, EXPERIMENTAL, GOOD, MODERATE, LOW, ERROR) %>% 
  arrange(desc(GOOD))

write.csv(VEGA_summary, "../data/excel_references/QSAR_output/VEGA_summary.csv", row.names = F)

# Perform Species averages across the full QSAR Dataset
VEGA_EC10_LQ <- VEGA_EC10 %>%
  mutate(
    Fish_avg = rowMeans(.[,grepl(paste(c(" Fish_Chronic_EC10eq", "Fathead_Minnow_Chronic_EC10eq", "Guppy_Chronic"), collapse = "|"), colnames(VEGA_EC10))], na.rm = T),
    Daphnia_avg = rowMeans(.[,grepl("D.magna_Chronic_EC10eq", colnames(VEGA_EC10))], na.rm = T),
    Algae_avg = rowMeans(.[,grepl("Algae_Chronic_EC10eq", colnames(VEGA_EC10))], na.rm = T),
    ) %>% 
  filter_at(vars(Fish_avg, Daphnia_avg, Algae_avg), all_vars(!is.nan(.)))%>%
  # Calculating EC20EC10eq for VEGA estimations
  # Need to first perform a per species average. then a per substance average. Are the models based on the same species? need to dig down and check.
  rowwise() %>% 
  mutate(VEGA_log_Mean = mean(log10(c(Fish_avg, Daphnia_avg, Algae_avg)), na.rm = TRUE),
         sd_VEGA_log_Mean = sd(log10(c(Fish_avg, Daphnia_avg, Algae_avg)), na.rm = TRUE), 
         ) %>% 
  ungroup() %>% 
  mutate(logHC20EC10eq_VEGA = VEGA_log_Mean + (sd_VEGA_log_Mean * -0.842),
         CRF_VEGA = 0.2/10^logHC20EC10eq_VEGA) # Concentration-response slope factor calculation based on all available data)

# Perform Species averages across the High-quality QSAR Dataset
VEGA_EC10_HQ <- VEGA_EC10 %>% 
  mutate(
    Fish_Chronic_EC10eq_IRFMN_mgL = case_when(Fish_Acute_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ as.numeric(Fish_Chronic_EC10eq_IRFMN_mgL)),
    Fish_Chronic_EC10eq_NIC_mgL = case_when(Fish_Acute_NIC_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fish_Chronic_EC10eq_NIC_mgL),
    Fish_Chronic_EC10eq_KNN_mgL = case_when(Fish_Acute_KNN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fish_Chronic_EC10eq_KNN_mgL),
    Fish_Chronic_EC10eq_IRFMN.Combase_mgL = case_when(Fish_Acute_IRFMN.Combase_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fish_Chronic_EC10eq_IRFMN.Combase_mgL),
    Fathead_Minnow_Chronic_EC10eq_EPA_mgL = case_when(Fathead_Minnow_Acute_EPA_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fathead_Minnow_Chronic_EC10eq_EPA_mgL),
    Fathead_Minnow_Chronic_EC10eq_KNN.IRFMN_mgL = case_when(Fathead_Minnow_Acute_KNN.IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fathead_Minnow_Chronic_EC10eq_KNN.IRFMN_mgL),
    D.magna_Chronic_EC10eq_IRFMN_mgL = case_when(D.magna_Acute_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ D.magna_Chronic_EC10eq_IRFMN_mgL),
    D.magna_Chronic_EC10eq_EPA_mgL = case_when(D.magna_Acute_EPA_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ D.magna_Chronic_EC10eq_EPA_mgL),
    D.magna_Chronic_EC10eq_IRFMN.Combase_mgL = case_when(D.magna_Acute_IRFMN.Combase_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ D.magna_Chronic_EC10eq_IRFMN.Combase_mgL),
    Guppy_Chronic_EC10eq_KNN.IRFMN_mgL = case_when(Guppy_Acute_KNN.IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Guppy_Chronic_EC10eq_KNN.IRFMN_mgL),
    Algae_Chronic_EC10eq_IRFMN_mgL = case_when(Algae_Acute_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Algae_Chronic_EC10eq_IRFMN_mgL),
    Algae_Chronic_EC10eq_ProtoQSAR.Combase_mgL = case_when(Algae_Acute_ProtoQSAR.Combase_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Algae_Chronic_EC10eq_ProtoQSAR.Combase_mgL),
    Fish_Chronic_EC10eq_IRFMN_NOEC_mgL = case_when(Fish_Chronic_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Fish_Chronic_EC10eq_IRFMN_NOEC_mgL),
    D.magna_Chronic_EC10eq_IRFMN_NOEC_mgL = case_when(D.magna_Chronic_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ D.magna_Chronic_EC10eq_IRFMN_NOEC_mgL),
    Algae_Chronic_EC10eq_IRFMN_NOEC_mgL = case_when(Algae_Chronic_IRFMN_eval %in% c("LOW", "EXPERIMENTAL") ~ as.numeric(NA), TRUE ~ Algae_Chronic_EC10eq_IRFMN_NOEC_mgL)
    ) %>% 
  mutate(across(ends_with("_eval"), ~ gsub("LOW|EXPERIMENTAL", as.numeric(NA), .))) %>% 
  mutate(
    Fish_avg = rowMeans(.[,grepl(paste(c(" Fish_Chronic_EC10eq", "Fathead_Minnow_Chronic_EC10eq", "Guppy_Chronic"), collapse = "|"), colnames(VEGA_EC10))], na.rm = T),
    Daphnia_avg = rowMeans(.[,grepl("D.magna_Chronic_EC10eq", colnames(VEGA_EC10))], na.rm = T),
    Algae_avg = rowMeans(.[,grepl("Algae_Chronic_EC10eq", colnames(VEGA_EC10))], na.rm = T),
    ) %>% 
  filter_at(vars(Fish_avg, Daphnia_avg, Algae_avg), all_vars(!is.nan(.)))%>%
  # Calculating EC20EC10eq for VEGA estimations
  # Need to first perform a per species average. then a per substance average. Are the models based on the same species? need to dig down and check.
  rowwise() %>% 
  mutate(VEGA_log_Mean = mean(log10(c(Fish_avg, Daphnia_avg, Algae_avg)), na.rm = TRUE),
         sd_VEGA_log_Mean = sd(log10(c(Fish_avg, Daphnia_avg, Algae_avg)), na.rm = TRUE), 
         ) %>%  
  ungroup() %>% 
  mutate(logHC20EC10eq_VEGA = VEGA_log_Mean + (sd_VEGA_log_Mean * -0.842),
         CRF_VEGA = 0.2/10^logHC20EC10eq_VEGA) # Concentration-response slope factor calculation based on all available data)

write.csv(VEGA_EC10_LQ, "../data/excel_references/QSAR_output/VEGA_EC10_LQ.csv", row.names = F)
write.csv(VEGA_EC10_HQ, "../data/excel_references/QSAR_output/VEGA_EC10_HQ.csv", row.names = F)
```


## statistical comparisons of VEGA QSAR data <-> Empirical data 
```{r}
# Loading empirical data
HESTIA_HC20_dataset <- read.csv("../results/HESTIA_HC20_dataset.csv")
# Comparing Experimental to Estimated data (ECOTOX ==/== VEGA_QSAR)

# defining a dataset with merged VEGA estimations and empirical data
plot_dataset <- left_join(x = HESTIA_HC20_dataset %>% 
                            select(CAS.Number, HC20EC10eq, HC20) %>% 
                            filter(!is.na(HC20)),
                          y = VEGA_EC10_LQ %>% 
                              select(CAS.Number, logHC20EC10eq_VEGA, CRF_VEGA),
                          by = "CAS.Number") %>% 
                  mutate(ratio_exp_est = CRF_VEGA/HC20)%>% 
                            filter(!is.na(ratio_exp_est))

plot_dataset_HQ_Data <- left_join(x = HESTIA_HC20_dataset %>% 
                            select(CAS.Number, HC20EC10eq, HC20) %>% 
                            filter(!is.na(HC20)),
                          y = VEGA_EC10_HQ %>% 
                              select(CAS.Number,logHC20EC10eq_VEGA, CRF_VEGA),
                          by = "CAS.Number") %>% 
                  mutate(ratio_exp_est = CRF_VEGA/HC20) %>% 
                            filter(!is.na(ratio_exp_est))

# Calculating absolute differences between estimated and empirical data.
QSAR_emp_abs_diff_df <- plot_dataset_HQ_Data %>% 
  mutate(
    abs_diff = abs(HC20-CRF_VEGA),
    log_abs_diff = abs(HC20EC10eq-logHC20EC10eq_VEGA)
         ) %>% 
  arrange(desc(abs_diff)) 

write.csv(QSAR_emp_abs_diff_df, "../data/excel_references/QSAR_output/QSAR_emp_abs_diff_df.csv", row.names = F)

# plotting histogram over the absolute difference ratio
QSAR_emp_abs_diff_df %>% 
  ggplot(aes(x = abs_diff))+
  geom_histogram()+
  scale_y_log10()+
  scale_x_log10()

####
# Building a linear model for the VEGA-empirical comparisons
# 1. Confirming data assumptions of linearity. A coefficient close to -1 or 1 means linearity of data, 0 means very low linear correlation
  # This finds the correlation coefficient between the CRF_all and CRF_VEGA columns of the data frame.
cor.test(plot_dataset$HC20, plot_dataset$CRF_VEGA)
  
# 2. Building a model on training data  
# This creates a simple linear regression model where CRF_VEGA is the outcome variable and CRF_all is the predictor variable. The data used is a data frame named plot_dataset
model <- lm(CRF_VEGA ~ HC20, data = plot_dataset)
# 3. Assessing the model’s fit
# RSE can be found in the summary of a model.
summary(model)
# 4. Analyzing model results.
# This finds the R Squared value of a linear regression model named model.
summary(model)$r.squared

####
#For the HQ_Dataset
####
#Building a linear model for the VEGA-empirical comparisons
# 1. Confirming data assumptions of linearity. A coefficient close to -1 or 1 means linearity of data, 0 means very low linear correlation
  # This finds the correlation coefficient between the CRF_all and CRF_VEGA columns of the data frame.
cor.test(plot_dataset_HQ_Data$CRF_VEGA, plot_dataset_HQ_Data$HC20)
  
# 2. Building a model on training data  
# This creates a simple linear regression model where CRF_VEGA is the outcome variable and CRF_all is the predictor variable. The data used is a data frame named plot_dataset
model_2 <- lm(CRF_VEGA ~ HC20, data = plot_dataset_HQ_Data)
# 3. Assessing the model’s fit
# RSE can be found in the summary of a model.
summary(model_2)
# 4. Analyzing model results.
# This finds the R Squared value of a linear regression model named model.
summary(model_2)$r.squared
####
```

# Data visualization
```{r}
# Comparing CRF ratios against each other. from experimental vs. estimated data.
plot_dataset %>% 
      arrange(desc(ratio_exp_est)) %>% 
    ggplot(aes(x = reorder(CAS.Number, -ratio_exp_est) , y = ratio_exp_est)) +
    geom_point(size = 1) +
    geom_line(aes(y = 1), color = "red")+
    geom_hline(yintercept = c(1E2, 1, 1E-2), linetype="dashed", color = "red") + # Better visualization of how much data is within 4 orders of magnitude variation around ratio = 1.
    scale_y_log10()

# Comparing data points of CRF_all & CRF_vega
 QSAR_plot <- plot_dataset %>% 
    ggplot(aes(x = HC20, y = CRF_VEGA)) +
    geom_point(size = 1) +
    #geom_smooth(method = "lm", color ="red", size = 1) +
    geom_text(aes(x = 500, y = 1000), label = print(paste0("R^2 =", summary(model)$r.squared))) +
    #geom_abline(intercept = 0, slope = 1, color = "blue") +
    scale_y_log10() +
    scale_x_log10() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank(), axis.line = element_line(colour = "black")) +
    ylab("CRF VEGA QSAR") +
    xlab("CRF empirical data") +
     ggtitle(paste("Comparison between Empirical data to (all) QSAR estimations\n of HC20-values", ", ", nrow(plot_dataset %>% filter(!is.na(CRF_VEGA))), " substances", sep = ""))

QSAR_plot 
    #ggsave("figures/QSAR_comparison_LQ.png", QSAR_plot, dpi = 300)

 # Comparing data points of CRF_all & CRF_vega for HQ_data
QSAR_plot_HQ <- plot_dataset_HQ_Data %>% 
    ggplot(aes(x = HC20, y = CRF_VEGA)) +
    geom_point(size = 1) +
    #geom_smooth(method = "lm", color ="violet", size = 1) +
    geom_text(aes(x = 500, y = 1000), label = print(paste0("R^2 =", summary(model_2)$r.squared))) +
    #geom_abline(intercept = 0, slope = 1, color = "blue") +
    scale_y_log10() +
    scale_x_log10() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank(), axis.line = element_line(colour = "black")) +
    ylab("CRF VEGA QSAR") +
    xlab("CRF empirical data") +
    ggtitle(paste("Comparison between Empirical data to (HQ) QSAR estimations\n of HC20-values", ", ", nrow(plot_dataset_HQ_Data %>% filter(!is.na(CRF_VEGA))), " substances", sep = ""))

QSAR_plot_HQ 
    ggsave("figures/QSAR_comparison_HQ.png", QSAR_plot_HQ, dpi = 300)


  
```


### Comparisons removed low quality 
VEGA_GOOD <-> Experimental (ECOTOX)
```{r}
# Comparing Experimental to Estimated data (ECOTOX ==/== VEGA_QSAR)

# defining a dataset with merged VEGA estimations and empirical data
plot_dataset_good <- merge(x = HC20_dataset,
                          y = VEGA_GOOD %>% 
                              select(-c(ID, SMILES, SMILES_VEGA)),
                          by = "CAS.Number") %>% 
                  filter(!is.na(CRF_VEGA),
                         !is.na(CRF_best)) %>% 
                  mutate(ratio_exp_est = CRF_best/CRF_VEGA)

#Building a linear model for the VEGA-empirical comparisons
  # 1. Confirming data assumptions of linearity. A coefficient close to -1 or 1 means linearity of data, 0 means very low linear correlation
    # This finds the correlation coefficient between the CRF_all and CRF_VEGA columns of the data frame.
  cor.test(plot_dataset_good$CRF_all, plot_dataset_good$CRF_VEGA)
    # ok, so the coefficient is -0.03341369. very close to 0 here as well, but on the other side of 0.
  # 2. Building a model on training data  
  # This creates a simple linear regression model where CRF_VEGA is the outcome variable and CRF_all is the predictor variable. The data used is a data frame named plot_dataset
  model_good <- lm(CRF_VEGA ~ CRF_all, data = plot_dataset_good)
  
  # 3. Assessing the model’s fit
  # RSE can be found in the summary of a model.
  summary(model_good)
  # 4. Analyzing model results.
  # This finds the R Squared value of a linear regression model named model.
  summary(model_good)$r.squared

# Comparing CRF ratios against each other. from experimental vs. estimated data.
plot_dataset_good %>% 
      arrange(desc(ratio_exp_est)) %>% 
    ggplot(aes(x = reorder(CAS.Number, -ratio_exp_est) , y = ratio_exp_est)) +
    geom_point(size = 1) +
    geom_line(aes(y = 1), color = "red")+
    geom_hline(yintercept = c(1E2, 1, 1E-2), linetype="dashed", color = "red") + # Better visualization of how much data is within 4 orders of magnitude variation around ratio = 1.
    scale_y_log10()
# Comparing data points of CRF_all & CRF_vega
  plot_dataset_good %>% 
    ggplot(aes(x = CRF_all, y = CRF_VEGA)) +
    geom_point(size = 1) +
    geom_text(aes(x = 250, y = 10), label = print(paste0("R^2 =", summary(model_good)$r.squared))) +
    geom_smooth(method = "lm", color ="red", size = 1) +
    geom_abline(intercept = 0, slope = 1, color = "blue") +
    scale_y_log10(breaks = c(1E-3, 1E-2, 1E-1, 1E-0, 1E1, 1E2, 1E3)) +
    scale_x_log10(breaks = c(1E-3, 1E-2, 1E-1, 1E-0, 1E1, 1E2, 1E3)) +
    theme_light(base_size = 8) +
    ylab("CRF VEGA QSAR") +
    xlab("CRF empirical data") +
    ggtitle("Empirical-QSAR impact indicator comparison of substances \n 
            low quality QSAR data removed. Blue line = 1:1 comparison")

```

### Exploring QSAR methods
The applicability of toxicological effect data derived from quantitative structure–activity relationship (QSAR) models generated are explored using VEGA software application [@Benfenati2013VEGAQSARAI]. Estimated effect concentrations are based on substances’ SMILES configuration and the estimated effect data are reported with the unit $mg\text{ }l^{-1}$ along with a quality evaluation of the prediction based on the similarity to compared compounds. Model estimation quality is calculated as a compounded similarity index which evaluates similarities to validated training datasets of chemicals as an "applicability domain" (AD) index and is reported as "EXPERIMENTAL", "GOOD", and "MODERATE", "LOW", or "ERROR" for each chemical respectively [@floris2014generalizable]. Since training datasets only contain organic substances, multi-constituent or metal-complexes will be given "ERROR" status. Fifteen selected QSAR models were applied across the `r nrow(read_tsv("data/excel_references/CAS_CID_list_final.txt", col_names = F)[,2] %>% filter(!is.na(.)))` chemicals with SMILES configuration available (see Table \@ref(tab:QSARModels)). Full documentation of models, training data and AD index parameters is provided at the [VEGA QSAR online platform](https://www.vegahub.eu/portfolio-item/vega-qsar-models-qrmf/). Estimated effect concentrations were subsequently transformed into EC10eq using the same regression coefficients as for the empirical dataset: 0.6 for Chronic NOEC to chronic EC10eq conversions and 2 for Acute E(L)C50 to chronic EC10eq. $log(HC20_{EC10^{eq}})$ and $CRF_{HC20}$ values are subsequently calculated according to the methodology used for the HESTIA empirical toxicological effect dataset. Here species-specific averages are applied across "algae", "D.magna", and "fish", which means that the number of species data to construct SSD models is not sufficient (number of species <5), therefore no SSDs are constructed, but HC20EC10eq-values are calculated using eq.1-7. One "high-quality" dataset is created from a subset of the QSAR estimations where only records with "EXPERIMENTAL", "GOOD", and "MODERATE" quality are selected as a complimentary analysis. Quality of all available predictions are measured as a "QSAR-Empirical match ratio" between the calculated HC20-values based on QSAR estimations ($HC20_{QSAR}$) and the HC20-values based on empirical records ($HC20_{emp}$) as $\frac{HC20_{QSAR}}{HC20_{emp}}$.   

### Investigating the applicability of QSAR models to estimate toxicological effect data  

```{r QSAR-lm-chunk}

CAS_SMILES_list <- read_tsv("../data/excel_references/CAS_CID_list_final.txt", col_names = F)
names(CAS_SMILES_list) <- c("CAS.Number", "SMILES")
CAS_SMILES_list_no_na <- CAS_SMILES_list %>% 
  filter(!is.na(SMILES))

QSAR_emp_abs_diff_df <- read.csv("../data/excel_references/QSAR_output/QSAR_emp_abs_diff_df.csv")
# fitting a linear model for the VEGA-empirical comparisons on HQ data
# 1. Confirming data assumptions of linearity. A coefficient close to -1 or 1 means linearity of data, 0 means very low linear correlation
  # This finds the correlation coefficient between the CRF_all and CRF_VEGA columns of the data frame.
# shapiro.test(QSAR_emp_abs_diff_df$logHC20EC10eq_VEGA)
# shapiro.test(QSAR_emp_abs_diff_df$HC20EC10eq)
# qqplot(QSAR_emp_abs_diff_df$HC20EC10eq, QSAR_emp_abs_diff_df$logHC20EC10eq_VEGA)
# correlation_test <- cor.test(QSAR_emp_abs_diff_df$HC20EC10eq, QSAR_emp_abs_diff_df$logHC20EC10eq_VEGA)

# 2. Building a model on training data  
# This creates a simple linear regression model where CRF_VEGA is the outcome variable and CRF_all is the predictor variable. The data used is a data frame named plot_dataset
lm_model <- lm(HC20EC10eq ~ logHC20EC10eq_VEGA, data = QSAR_emp_abs_diff_df)
# 3. Assessing the model’s fit
# RSE can be found in the summary of a model.
   #summary(lm_model)

# 4. Analyzing model results.
# This finds the R Squared value of a linear regression model named model.
r_value <- summary(lm_model)$r.squared
 # summary(lm_model)$coefficients
```

From the `r nrow(CAS_SMILES_list_no_na)` mono-constituent chemicals that could be matched to a SMILES annotation, the most prevalent outcome is low quality scoring chemicals, the KNN acute LC50 fish toxicity model producing the most good quality matches contrasted by the NIC acute LC50 fish toxicity model which produced no higher quality matches, apart from the chemicals present within the model's training data. A summarized overview of the QSAR estimations quality report in shown in Table \@ref(tab:QSARModels).  

```{r QSARModels}
# QSAR comparison to Empirical data df
QSAR_emp_abs_diff_df <-  read.csv("../data/excel_references/QSAR_output/QSAR_emp_abs_diff_df.csv")

median_diff_value <- QSAR_emp_abs_diff_df %>% summarise(median = median(abs_diff, na.rm = T))

# QSAR quality summary table
QSAR_table <- autofit(flextable(read.csv("../data/excel_references/QSAR_output/VEGA_summary.csv", header = T) %>% 
                                  mutate(QSAR_model = gsub("_eval", "", QSAR_model),
                                         QSAR_model = gsub("_", " ", QSAR_model)) %>% 
                                  rename(`QSAR model` = QSAR_model)))
QSAR_table %>%  
  set_caption("Summary of the QSAR models applied to the HESTIA toxicological dataset, with counts of model quality per QSAR model. 'ERROR'-column implies either ERROR-reported quality score, estimates are missing, or estimate = 0 mg/L") %>% 
  flextable::set_table_properties(layout = "autofit") %>% 
  fontsize(., size = 9, part = "all")

```


Only a small subset of chemicals are eligible to include for $log(HC20_{EC10^{eq}})$ calculations as a "high-quality" subset with `r nrow(QSAR_emp_abs_diff_df)` records where HC20-values are based on only "GOOD" and "MODERATE" quality are selected for analysis. Records marked as "EXPERIMENTAL" were removed to not compare data originating from the same source as the experimental records. When fitting a linear model to the calculated $log(HC20_{EC10^{eq}})$-values based on QSAR estimations ($log(HC20_{EC10^{eq}_{QSAR}})$) and $log(HC20_{EC10^{eq}})$-values based on empirical records ($log(HC20_{EC10^{eq}_{emp}})$) we see a strong relationship between the two datasets, but only `r round(r_value, 3)` % of the variability of $log(HC20_{EC10^{eq}_{QSAR}})$ is explained by $log(HC20_{EC10^{eq}_{emp}})$ (Figure \@ref(fig:QSAREmp) a)). Worth noting is the severe under-estimation in toxicity for the substances deemed most toxic from empirical data, highlighted in the red circle in Figure \@ref(fig:QSAREmp) a), where toxicity is underestimated by several orders of magnitude in the QSAR estimations. Figure \@ref(fig:QSAREmp) **b)** shows the distribution of relative difference between QSAR estimations to empirical data, presented on a log scale where the quality of all available predictions are measured as a "QSAR to empirical data ratio" ($R_{QSAR/Emp}$) between $log(HC20_{EC10^{eq}_{QSAR}})$ and the $log(HC20_{EC10^{eq}_{emp}})$ as  

\begin{equation}
\frac{logHC20EC10eq_{QSAR}}{logHC20EC10eq_{emp}} = R_{QSAR/Emp}
(\#eq:eq12)
\end{equation}

  
```{r QSAREmp, fig.dim = c(12, 6), fig.cap = "(TEST CAPTION)"}
# Comparing data points of CRF_all & CRF_vega for HQ_data
QSAR_plot_HQ <- QSAR_emp_abs_diff_df %>% 
    ggplot(aes(x = HC20EC10eq, y = logHC20EC10eq_VEGA)) +
    geom_point(size = 1) +
    geom_smooth(method = "lm", color ="blue", size = 1) +
    geom_text(aes(x = 2, y = 4), label = paste("R^2 =", round(r_value, 4))) +
    #geom_abline(intercept = 0, slope = 1, color = "blue") +
    #scale_y_log10() +
    #scale_x_log10() +
    geom_ellipse(aes(x0 = -4.8, y0 = -0.8, a = 2, b = 0.5, angle = pi / 6), color = "red", fill = NA, show.legend = FALSE) +
    theme(panel.grid.major = element_blank(),
          text = element_text(color = "black", family = "serif"), 
          panel.grid.minor = element_blank(),
          panel.background = element_blank(), 
          axis.line = element_line(colour = "black")) +
    xlab("logHC20EC10eq-values based on empirical records") +
    ylab("logHC20EC10eq-values based on estimated QSAR data") +
    labs(tag = "a)") +
    ggtitle(paste("Comparison between empirical data to (HQ) QSAR estimations\n of logHC20EC10eq-values, ", nrow(QSAR_emp_abs_diff_df), " chemicals", sep = ""))

# ggsave("figures/QSAR_comparison_HQ.png", QSAR_plot_HQ, dpi = 300)

hist_abs_diff <- QSAR_emp_abs_diff_df %>%
  ggplot(aes(x = log_abs_diff))+
  geom_histogram() +
  xlab("QSAR estimated to empirical data ratio") +
  labs(tag = "b)") +
  theme(panel.grid.major = element_blank(),
        text = element_text(color = "black", family = "serif"), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
  

grid.arrange(QSAR_plot_HQ, hist_abs_diff, ncol=2)
```

*Quantitative structure-activity relationships:*  
Complementing toxicological testing of animals with *in silico* simulations to derive quantitative structure-activity relationship estimates for chemical toxicity is a desirable approach for improving our understanding of the full range of impacts caused by anthropogenic activities. This as toxicological tests of chemicals are time consuming and expensive, while new chemicals are constantly introduced. Moreover, ethical aspects of exposing animals to potentially harmful chemicals also need to be considered. These QSAR models, however, are only as good as the training data and results from the current work show that when applying fifteen different QSAR models to the HESTIA inventory chemicals, many are too dissimilar to the models' training datasets and either fail to generate estimations or are deemed as low-quality estimations. 
 - "Models are outside of their applicability domain :)"  
Even more worrisome is that estimations of experimental, good and moderate quality are still not providing HC20-values within a reasonable error margin. When comparing QSAR HC20-values with HC20-values based on empirical data across `r nrow(QSAR_emp_abs_diff_df)` chemicals, the estimated HC20-values deviate substantially from the corresponding HC20-values derived from empirical data with errors up to `r formatC(QSAR_emp_abs_diff_df[1,7], format = "e", digits = 2)` $PAF\text{ } m^3/kg_{bioavailable}$ at the largest extreme, while the median difference is `r round(median_diff_value[1,1], 2)` $PAF\text{ } m^3/kg_{bioavailable}$.  data and data for additional chemicals are available (e.g in the REACH dossier) and gathering of data for *any other* chemicals using OECD QSAR Toolbox could be a straightforward task, with the here available R-scripts adapted for reading and wrangling data structured as OECD QSAR Toolbox-output.
