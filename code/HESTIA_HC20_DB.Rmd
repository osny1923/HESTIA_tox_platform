---
title: "HESTIA_Database_construction"
author: "Oskar"
date: "`r Sys.Date()`"
output: html_document
bibliography: references.bib
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(message = F, warning = F, echo = F)
# These libraries are used for analysis
  # install.packages("webchem")
  # install.packages("taxize")   # <- Installing the "taxize" library http://dx.doi.org/10.5281/zenodo.7097
  # install.packages("networkD3") <- For the Sankey flow chart visualization
  # install.packages("goeveg") # <- for simple coefficient of Variation calculation at summary of data
  # install.packages("webshot") # <- Saving the sankeyNetwork .html file to a .png
  library(rmarkdown)
  library(tidyverse)
  library(webchem)
  library(openxlsx)
  library(readr)
  library(kableExtra)
  library(taxize)
  library(ggpubr)
  library(networkD3)
  library(htmlwidgets)
  library(webshot)
```

# HESTIA ecotoxicological database 
\vspace{40mm}

Oskar Nyberg$^{1,\dagger}$, Reinout Heijungs$^{2,3}$, Patrik Henriksson$^{4,5,6}$

\vspace{20mm}
${^1}$ Department of Ecology, Environment and Plant Sciences, Stockholm University, Svante Arrhenius väg 20A, 104 05, Stockholm, Sweden  
${^2}$ Department of Operations Analytics, Vrije Universiteit, De Boelelaan 1105, 1081 HV, Amsterdam, The Netherlands  
${^3}$ Institute of Environmental Sciences, Leiden University, Van Steenisgebouw Einsteinweg 2, 2333 CC, Leiden, The Netherlands  
${^4}$ Stockholm Resilience Centre, Albanovägen 28, 106 91, Stockholm, Sweden  
${^5}$ WorldFish, Jalan Batu Maung, Batu Maung, 11960 Bayan Lepas, Pulau Pinang, Malaysia  
${^6}$ Beijer Institute of Ecological Economics, The Royal Swedish Academy of Science, Lilla Frescativägen 4 A, Stockholm, Sweden  

${\dagger}$ Corresponding author: [oskar.nyberg@su.se](mailto:oskar.nyberg@su.se); [nyberg.oskar@gmail.com](mailto:nyberg.oskar@gmail.com); [(+46) 735-351260](tel:+46735351260)


\newpage
### Abstract
We calculate characterization factors for chemicals with potential negative environmental impact by construct a ecotoxicological database all openly available 

\newpage

# HESTIA Database construction.
The starting point for constructing a database with ecotoxicological data to calculate characterization factors suited for the online life cycle assessment (LCA) application HESTIA ([http://HESTIA.earth](http://hestia.earth)) is the substance inventory acquired as the .csv file `Pesticide.AI`. This is a list of 16797 potentially harmful substances based on the United States Environmental Protection Agency's Substance Registry Services (USEPA SRS) inventory. (Probably). 

The first operation is to import this list of substances and select CAS registry numbers (CASRN) and substance names, as well as reformatting CASRN format from `CAS-XXXX-XX-X` to `XXXX-XX-X`. Then, we use the NCBI PubChem project to match CASRN and substance names to SMILES configuration with the intermediate step of acquiring PubChem substance IDs using the R package [Webchem](https://docs.ropensci.org/webchem/) [@Webchem_2020]
```{r}
# This step takes place in the `code/Translating_CAS_to_SMILES_via_PubChem.R`-file
# Output from this operation creates three files: a .csv doc "data/excel_references/CAS_CID_list_final.csv", a .txt file containing CASRN-SMILES matches: "data/excel_references/CAS_CID_list_final.txt", as well as five subsets from the previous .txt file named "data/excel_references/cas_smiles_list[XXXX-XXXXk].txt"
```

Based off of the CASRN-SMILES matches we take three actions: 1) query substance use info, to annotate use-types for each substance respectively `code/Pesticide_annotations.Rmd`, 2) query the OECD QSAR Toolbox [REF] for physicochemical properties for substances and subsequently read and wrangle data for a USEtox-friendly format `Physchem_read_wrangle_function`, and 3) query the OECD QSAR Toolbox [REF] for substances' aquatic ecotoxicological records. 
```{r Physchem info, echo=FALSE}
# Physchem wrangle function
source("../code/Physchem_read_wrangle_function.R")
# Processing and wrangling the raw data through function loaded above
# Note: When exporting data from OECD QSAR Toolbox, 38 chemicals are marked as private and not exported. 200 restricted chemicals are exported without data
Physchem_HESTIA <- Physchem_read_wrangle_function(read.csv("../data/QSAR_Toolbox_physchem_data_2023-07-11_RAW.csv", header = T, sep = "\t", na.strings = "", fileEncoding = "UTF-16LE",  stringsAsFactors = FALSE))
# Loading the slim version of the Pesticide annotations data for substance use properties and merge this here.
HESTIA_chem_list_slim <- read.csv("../results/HESTIA_chem_list_slim.csv")

NEW_PHYSCHEM <- left_join(
  x = Physchem_HESTIA, 
  y = HESTIA_chem_list_slim, 
  by = "CAS.Number"
) %>% 
  select(CAS.Number, CanonicalSMILES, PesticideAI_name, 2:32) 

```


To generate EC20^EC10eq effect endpoints for chemicals i need data from  EC10, EC50 as well as LC and NOEC data.
for details on the treatment of input CAS numbers, how all available SMILES configurations were gathered and thereafter exported as 4k row long subsets.
This information on CAS and SMILES per substance was used as input into OECD QSAR Toolbox software where two distinct operations took place, 1) query for toxicological effect data, and 
Acquired metadata data gives an abundance of test information across ~ 450 columns, although the majority of these are redundant for the current purpose. Wrangling of the raw OECD QSAR Toolbox output takes place in `data/raw_data_read_and_wrangle.R` and is subsequently imported as a data frame for treatment and filtering. 
In several steps of these filtering operations, physicochemical data is required, which is available for `r nrow(NEW_PHYSCHEM)``

Reading it here, because I need some of the physicochemical data and the pesticide annotations below (for pesticides, ACR annotations are 2.2, not standard 2, according to USEtox manual!)

## Raw data wrangling
Importing, filtering and wrangling the ecotoxicological effect data from QSAR data output, including relevant metadata that can act as quality control. In this operation the OECD QSAR Toolbox output gets read in and a first step of harmonizing the data set. The files have different lengths and number of columns, which forces me to select a set of defined columns. Additionally, duplicates and completely empty records have been removed to have a neater data set to work with.

```{r reading TOX data}
# Reading in the data input ready for wrangling. "Pre-filtered" implying that the data has been 
# Dependency -> "../data/raw_data_read_and_wrangle.R"
HESTIA_HC20_DB <- read.csv("../data/RAW_DB/HESTIA_HC20_DB_raw_toxdata.csv") %>% 
  select(-SMILES) %>% 
  mutate(Year = coalesce(Year, Publication.year)) %>% 
  select(-Publication.year)

```


## Which endpoints to include.
Saouter et al.(2022) defined 6 different conversion coefficients for chronic/acute EC50 -> chronic EC10 etc.
Leo Posthuma used several more, all ECx (1-20), records with the endpoints NOEC, LOEC, maximum acceptable toxicant concentration, EC0, EC5, EC10, and EC20 are marked as “chronic NOEC”, records with (EC) or (LC) endpoint ranging from 30 to 70% are marked as “acute EC50”
Acute/chronic definitions are available in Posthuma et al., 2019 (Table 1) and Aurisano et al., 2019 for algae, bacteria, unicellular animals, crustaceans, fish, molluscs/worms/etc. or in Aurisano
Harmonization and aggregation of endpoints  
[Aurisano et al., 2019, p. 2570]  
EC0, EL0, IC0, LC0, NOAEC, NOEC, NOEbC, NOErC, NOEL grouped into NOEC; EC10, IC10, LC10, LOEC grouped into EC10eq; EC50, EbC50, EbL50, ErC50, ErL50, IC50, LC50 grouped into EC50.
“We combined LOEC and EC10 for deriving extrapolation factors based on high uncertainties in the low range of species sensitivity distributions, rendering it difficult to treat LOEC and EC10 as separate metrics in statistical analyses (Iwasaki et al. 2015; King et al. 2017).” [Aurisano et al., 2019, p. 2571]

```{r Endpoint selection}
## Applying conversions for Endpoints
source("../code/EC10eq_conversion_functions.R")

HESTIA_HC20_DB_endpoint_conversions <- HESTIA_HC20_DB %>%
  mutate(Endpoint_conv = mapply(endpoint_conv_function, Endpoint)) 

```

### Values reported in range
Effect concentration qualifiers are used for some effect records
Based on similar work by Saouter et al., 2019, in cases where no mean value is reported, the following rules will be applied:
“A large majority of the results have a numeric value in the low range with a qualifier =, ca., >=, or >. In contrast, only a few tests have their results expressed in the higher ranges. The following selections were made to maximize the use of available data:   

1. When there is a lower range value with the descriptors ‘>=, ca., or empty’, the lowest value is selected. 
  If, within this group, a test has also a higher value, this higher value is ignored.  
  
2. All lower range values described as ‘>’ are ignored (n = `r nrow(1+1)`), unless the higher value is described as ‘=<’ (n= `r nrow(1+1)`observations). 
  In case of NOEC > than, the value was kept since it is still representing a concentration with no observed effect.  
  
3. All higher values described as ‘<' are ignored, unless the lower range value is described as ‘>=’. Then the lower value is used.  
4. When a lower range value is missing (0 or blank) and a higher value is available described as ‘<=’, the higher value is used.  

5. When a lower value is described as >= and the higher value is described as <=, the lowest value is used.  
6. Values expressed as ‘<’ are excluded (`r nrow(1+1)` test results).” [Saouter et al., 2018, p. 47]  

```{r}
HESTIA_HC20_DB_qualifier_filter <- HESTIA_HC20_DB_endpoint_conversions %>% 
  # Qualifiers, step one. in Saouter et al., 2018 "When there is a lower range value with the descriptors "ca., or empty’, the lowest value is selected. If, within this group, a test has also a higher value, this higher value is ignored.
  mutate(
    Value.MeanValue = case_when(Qualifier == "Data in range" | !is.na(Value.MinValue) ~ case_when(
      # If a qualifyer is stated as "ca.", "empty" or "=" values are drawn from the MinValue. 
      Value.MinQualifier %in% c("ca.", "=")| is.na(Value.MinQualifier) ~ Value.MinValue,
      # In case of NOEC > than, the value was kept since it is still representing a concentration with no observed effect. 
      Value.MinQualifier == ">" ~ case_when(
        Endpoint_conv == "NOEC" ~ Value.MinValue, 
        TRUE ~ "ignore"),
      Value.MinQualifier == "<" ~ "ignore"),
        TRUE ~ Value.MeanValue)
    ) 

sumRecRem <- HESTIA_HC20_DB_endpoint_conversions %>% 
  filter(Qualifier == "Data in range"| !is.na(Value.MinValue)) %>% 
  count(Value.MinQualifier) %>% 
  mutate(Value.MinQualifier = case_when(is.na(Value.MinQualifier) ~ "No qualifier", TRUE ~ Value.MinQualifier)) %>% 
  left_join( 
    x = ., 
    y = HESTIA_HC20_DB_endpoint_conversions %>% 
      filter(Qualifier == "Data in range" | !is.na(Value.MinValue)) %>% 
      count(Value.MinQualifier, Endpoint_conv) %>% 
      mutate(Value.MinQualifier = case_when(is.na(Value.MinQualifier) ~ "No qualifier", TRUE ~ Value.MinQualifier)) %>% 
      pivot_wider(., id_cols = Value.MinQualifier, names_from = Endpoint_conv, values_from = n),  
    by = "Value.MinQualifier") %>% 
  rename(Total = n) %>% 
  left_join(
    x = ., 
    y = HESTIA_HC20_DB_qualifier_filter %>% 
          filter(Value.MeanValue == "ignore") %>% 
          count(Value.MinQualifier) %>% 
          rename(Removed = n) %>% 
    mutate(Value.MinQualifier = case_when(is.na(Value.MinQualifier) ~ "No qualifier", TRUE ~ Value.MinQualifier)), 
    by = "Value.MinQualifier") 

rbind(sumRecRem,
      data.frame(
        Value.MinQualifier = "(Total) records where low range effect value is used", 
        Total = sum(sumRecRem$Total),
        EC10 = sum(sumRecRem$EC10),
        EC50 = sum(sumRecRem$EC50),
        NOEC = sum(sumRecRem$NOEC),
        Removed = as.numeric(NA))
      ) %>% 
  write.csv(., "../data/excel_references/summary table for value.qualifiers.csv", row.names = F)

HESTIA_HC20_DB_qualifier_filter <- HESTIA_HC20_DB_qualifier_filter %>% 
  # Removing all data with where qualifier filter is set to "ignore"
  filter(is.na(Value.MeanValue) | !Value.MeanValue == "ignore") 

```


## Additional quality filter
Some data have annotations where Control.Type is annotated as "inconclusive" or "unsatisfactory".
Additional filtering operations dependent on outlier inspection an identification of "odd" data
```{r}
# Preparing removal of algae and "others" in paper where these groups have attributed NOEC values as posterior attribute.
{
taxonomy <- read.csv("../data/Taxonomy/Species_taxonomy.csv") 
paper_taxa <- HESTIA_HC20_DB_qualifier_filter %>% 
  filter(grepl("A Freshwater Mesocosm Study into the Effects of the Neonicotinoid Insecticide Thiamethoxam at Multiple Trophic Levels", Title))
Algae_removal_df <- taxonomy %>% 
  filter(Test.organisms..species. %in% paper_taxa$Test.organisms..species.) %>% 
  filter(Taxonomy.Group %in% c("Algae", "Others")) %>% 
  pull(Test.organisms..species.) 
}

HESTIA_HC20_DB_Control.Type_filter <- HESTIA_HC20_DB_qualifier_filter %>% 
  filter(
    # Removing data based on insufficient/unsatisfactory controls
    !Control.type %in% c("Insufficient", "Unsatisfactory"),
    # Removing QSAR in title
    !grepl("QSAR", x = Title, ignore.case = T),
    # Removing bioassay in title
    !grepl("bioassay", x = Title, ignore.case = T),
    # Removing Quantitative in title
    !grepl("Quantitative", x = Title, ignore.case = T),
    # Removing QSAR in experimental design annotation
    !grepl("QSAR", x = Experimental.design, ignore.case = T),
    # Removing bioassay in experimental design annotation
    !grepl("bioassay", x = Experimental.design, ignore.case = T),
    # Removing QSAR study
    !grepl("Assessment of Aquatic Experimental Versus Predicted and Extrapolated Chronic Toxicity Data of Four Structural Analogues", Title),
    # Removing QSAR study
    !grepl("Effects of Chlorpyrifos, Carbendazim, and Linuron on the Ecology of a Small Indoor Aquatic Microcosm", Title),
    # Removing QSAR study
    !grepl("Altenburger,R., H. Walter, and M. Grote", Title),
    # Removing QSAR study
    !grepl("PREDICTING MODES OF TOXIC ACTION FROM CHEMICAL STRUCTURE: ACUTE TOXICITY IN THE FATHEAD MINNOW", Title),
    # Data entered incorrectly, mixing cardiovascular injections with soaking solutions, also, data reported as minimum non-lethal concentration is entered as EC10. Remove all of these.
    !grepl("Human Cardiotoxic Drugs Delivered by Soaking and Microinjection Induce Cardiovascular Toxicity in Zebrafish", Title),
    # Data on species-specific toxicity entered incorrectly, attributing D magna toxicity to S. capricirnutum.
    !grepl("A Multi-Battery Toxicity Investigation on Fungicides", Title),
    # Bioassay test-results
    !grepl("Rainbow Trout Larvae Compared with Daphnia", Title),
    # No source available, yet substance 107-21-1 from this study causes an extreme outlier
    !grepl("GERISH", Title),
    # 95% CI has one report of negative conventrations, which the qualifyer filter above selects. removing all data
    !grepl("Acute Effects of Binary Mixtures of Imidacloprid and Tebuconazole on 4 Freshwater Invertebrates", Title),
    # 95% CI has one report of negative conventrations, which the qualifyer filter above selects. removing all data
    !grepl("Relative Chronic Sensitivity of Neonicotinoid Insecticides to Ceriodaphnia dubia and Daphnia magna", Title),
    #Presents ridiculously low effect concentrations from micrplastic study on D. rerio embryos concentrations reported are used as an effect test result! incorrect entry into database
    !grepl("Multi-Laboratory Hazard Assessment of Contaminated Microplastic Particles by Means of Enhanced Fish Embryo Test with the Zebrafish", Title),
    # Study runs toxicological effect testing across a range of temperatures, leading to skewed data output.
    !grepl("Water Toxicology and Radioecology. Acute Toxicity of Heavy Metals to Aquatic Invertebrates at Different Temperatures", Title),
    # Duplicate data exists from the same author, also recorded in "Little, L.W., J.C. Lamb III, M.A. Chillingworth, and W.B. Durkin, Acute Toxicity of Selected Commercial Dyes to the Fathead Minnow and Evaluation of Biological Treatment for Reduction of Toxicity"
    !grepl("Acute Toxicity of 46 Selected Dyes to the Fathead Minnow, Pimephales promelas", Title),
    # The Japan MoE Ecotoxicological tests on chemical Hexabromobenzene, CASRN=87-82-1, is reported with data 6 orders of magnitude from all other data, and the specific test report is not to traceable.
    Database != "Aquatic Japan MoE" | CAS.Number != "87-82-1",
    # Removal of algae and "others" in paper where these groups have attributed NOEC values as posterior attribute.
    !grepl("A Freshwater Mesocosm Study into the Effects of the Neonicotinoid Insecticide Thiamethoxam at Multiple Trophic Levels", Title) | !Test.organisms..species. %in% Algae_removal_df
  )


```

## Test media (Freshwater & culture media filter)
Also, correcting the missing test media records, to match with identical species' test media.
```{r}
# Creating a list of species test medium annotations, to complement the ones missing annotations and exclude salt water species. 
Missing_media_list <- HESTIA_HC20_DB_Control.Type_filter %>% 
  left_join(x = .,
  # Joining with the (in part) manually curated taxonomy list for the HESTIA DB
    read.csv("../data/Taxonomy/Species_taxonomy.csv"), 
    by = "Test.organisms..species.") %>% 
  filter(!is.na(Media.type)) %>% 
  distinct(Test.organisms..species., .keep_all = T) %>% 
  select(Test.organisms..species., Media.type) %>% 
  rename(Media.correct= Media.type) %>% 
  rbind(data.frame(Test.organisms..species. = "Pseudokirchneriella subcapitata",
                   Media.correct = "Fresh water"))


HESTIA_HC20_DB_water_filter <- HESTIA_HC20_DB_Control.Type_filter %>% 
  mutate(
    Media.type = gsub(" ", "", Media.type),
    Media.type = coalesce(
      Media.type, Water.type)) %>% 
  left_join(
    x = ., 
    y = Missing_media_list, 
    by = "Test.organisms..species."
  ) %>% 
  # correcting the media type, when it is missing, based on other identical species' media type annotations
  mutate(Media.type = case_when(is.na(Media.type) ~ coalesce(Media.type, Media.correct), TRUE ~Media.type)) %>% 
  # Filtering out all "saltwater" and "no substrate" tests. 
  filter(!Media.type %in% c("Saltwater", "Nosubstrate"),
         !is.na(Media.type)
         ) 

HESTIA_HC20_DB_Control.Type_filter %>% 
  left_join(
    x = ., 
    y = Missing_media_list, 
    by = "Test.organisms..species."
  ) %>% 
  mutate(Media.type = case_when(is.na(Media.type) ~ coalesce(Media.type, Media.correct), TRUE ~Media.type)) %>% 
  mutate(
    Media.type = gsub(" ", "", Media.type),
    Media.type = coalesce(
      Media.type, Water.type)) %>% 
  # correcting the media type, when it is missing, based on other identical species' media type annotations
    count(Media.type) %>% 
  write.csv(., "../data/excel_references/Media_type_counts.csv", row.names = F)
```

## Effect Criterion selection 
Posthuma et al., 2019, selected few effect criterion where: 
"... records with the endpoints NOEC, lowest-observed-effect concentration, maximum acceptable toxicant concentration, EC0, EC5, EC10, and EC20 are marked as “chronic NOEC” when they have an appropriate taxon-dependent test duration (see Table 1) and population-relevant effect criterion (e.g., reproduction, growth, population growth, and development, next to mortality and immobility); and records with a sublethal (EC) or lethal endpoint ranging from 30 to 70% are marked as “acute EC50” when they have an appropriate taxon-dependent test duration (see Table 1) and effect criterion (e.g., mortality and immobility).
However, Posthuma et al. also clustered NOEC, LOEC, EC 0-20 into one "Chronic NOEC"-category and all EC 30-70 into one Acute EC50 category. 


We decide to select endpoint criterions based on expert consultation with dr. Andreu Rico
```{r}
HESTIA_HC20_DB_effect_crit_filter <- HESTIA_HC20_DB_water_filter %>% 
filter(Effect %in% c(
  "Behavior", "Growth", "Intoxication", "Population", "Reproduction", 
  "Acute", "Cell(s)", "Growth Rate", "Mortality", "Feeding Behavior",
  "Biomass", "Body Weight", "Chronic", "Frond Number", "Development", 
  "Mobility","Seedling Emergence", "Immobilisation", "Behaviour" 
  ) )

HESTIA_HC20_DB_effect_crit_filter %>% 
  group_by(Effect) %>% 
  summarise(n = n()) %>% 
  arrange(desc(n)) %>% 
  write.csv(., "../data/excel_references/summary_table_effect_crit.csv", row.names = F)

```

## Taxonomy wrangling

List of taxonomy descriptions is finalized. (code available in "code/Taxonomy_wrangling.Rmd")
Saved as file: "Final_Taxonomy_dataset.xlsx"
This contains 3503 species taxa-annotations with taxonomic group classifications as well.
Importing taxonomic descriptions and merging with the main data set

@Taxize is used (and have been added to the references.bib)
Citing taxize: `taxize_cite(fxn='taxize')`

```{r, warning=FALSE}

# Removing poor taxonomic descriptions and Species data annotated at higher taxonomic level. 
HESTIA_HC20_DB_taxonomy_filter <-  HESTIA_HC20_DB_effect_crit_filter %>% 
  left_join(x = .,
  # Joining with the (in part) manually curated taxonomy list for the HESTIA DB
    read.csv("../data/Taxonomy/Species_taxonomy.csv"), 
    by = "Test.organisms..species.") %>%
  filter(!is.na(Species),
         !is.na(Taxonomy.Group),
         !is.na(Phylum))

# Overview of the filtered out species, or genus and higher taxonomy rather...
HESTIA_HC20_DB_effect_crit_filter %>%
  left_join(x = .,
  # Joining with the (in part) manually curated taxonomy list for the HESTIA DB
    read.csv("../data/Taxonomy/Species_taxonomy.csv"),
    by = "Test.organisms..species.") %>%
  filter(is.na(Taxonomy.Group) | is.na(Species), is.na(Phylum)) %>%
  count(Test.organisms..species., sort = T) %>% 
  write.csv(., "../data/Taxonomy/filtered_out_species.csv", row.names = F)

```


##  Harmonize test durations and test concentration units and transform test concentrations into mg/L measurements.
Filter out data that is not convertable into correct time units or concentration formats.

effect concentration conversions needs a revision:
 - #For toxic endpoints, are milligrams per liter (mg / L) equivalent to parts per million (ppm)?
The endpoint concentrations for regulated toxic substances under the risk management program rule (40 CFR Part 68 Appendix A) are listed in units of milligrams per liter (mg/L).  Is this equivalent to parts per million (ppm)?
No, mg/L is not always equivalent to ppm.  Whereas ppm is a volume-to-volume or mass-to-mass ratio, mg/l is a mass-to-volume relationship.  To convert from units of mg/L to ppm, use the following equation.  Endpoint (ppm) = [Endpoint (mg/L) x 1000 x 24.5] / [Molecular Weight]  EPA has included the RMP toxic endpoints in both ppm and mg/L in Appendix B of the Risk Management Program Guidance for Offsite Consequence Analysis (EPA550-B-99-009, April, 1999).#

Hence, to convert ppm (or ppb to mg/L, I need to redo the conversions. 
Endpoint (ppm) = [Endpoint (mg/L) x 1000 x 24.5] / [Molecular Weight] -->
Endpoint (ppm) x Molecular Weight / 1000 x 24.5 = Endpoint (mg/L) 
```{r dur_and_val harmonization}

HESTIA_HC20_DB_unit_and_value_conv <- HESTIA_HC20_DB_taxonomy_filter %>% 
  left_join(
    x = .,
    y = NEW_PHYSCHEM %>% 
      select(CAS.Number, MW.g.mol), 
    by = "CAS.Number") %>%
  # Some mean value cells are empty, but can be calculated from the min and max value
  mutate(
  # replacing excel-format commas for dots.
    Value.MeanValue = gsub(pattern = ",", ".", Value.MeanValue), 
    # Converting effect concentrations into numeric data
    Value.MeanValue = as.numeric(Value.MeanValue), 
    # selecting values of Exposure duration as the determined duration, but when missing, test duration is used.
    Duration.MeanValue = case_when(
      is.na(Exposure.duration.MeanValue) & !is.na(Duration.MeanValue) ~ Duration.MeanValue, 
      TRUE ~ Exposure.duration.MeanValue),
    # selecting Units of Exposure.duration when "original" duration is missing
    Duration.Unit = case_when(
      is.na(Exposure.duration.Unit) & !is.na(Duration.Unit) ~ Duration.Unit, 
      TRUE ~ Exposure.duration.Unit),               
    # Converting Test duration values into numeric data
    Duration.MeanValue = as.numeric(Duration.MeanValue),
    # Converting test-duration to a coherent unit (hour)
    Time.Hours = case_when(
      Duration.Unit == "Second(s)" ~ Duration.MeanValue/3600,
      Duration.Unit == "min" ~ Duration.MeanValue/60,
      Duration.Unit == "h" ~ Duration.MeanValue,
      Duration.Unit == "d" ~ Duration.MeanValue*24,
      Duration.Unit == "wk" ~ Duration.MeanValue*(24*7),
      Duration.Unit == "mo" ~ Duration.MeanValue*(24*30),
      Duration.Unit == "yr" ~ Duration.MeanValue*(24*365),
      TRUE ~ as.numeric(NA)
    ),
  # Converting all eligible values into a coherent unit (mg/L)
  Value.Unit = gsub(" ", "", as.character(Value.Unit)), 
  Value.mg_l = case_when(
    Value.Unit %in% c("µg/L", "ng/mL", "µg/dm³") ~ Value.MeanValue/1E3,
    Value.Unit == "ppb" ~ Value.MeanValue/1E3,
    Value.Unit %in% c("mg/L", "µg/mL", "g/m³", "mg/dm³","ppm", "µg/cm³") ~ Value.MeanValue,
    Value.Unit %in% c("ppm") ~ Value.MeanValue,
    Value.Unit == "µg/3.5L" ~ Value.MeanValue/0.000285714286,
    Value.Unit %in% c("ng/L","pg/mL", "µg/µL") ~ Value.MeanValue/1E6,
    Value.Unit %in% c("g/L", "g/dm³", "mg/mL", "µg/mm³") ~ Value.MeanValue*1E3,
    Value.Unit == "µg/10L" ~ Value.MeanValue/1E4,
    Value.Unit == "pg/L" ~ Value.MeanValue/1E9,
    Value.Unit == "g/mL" ~ Value.MeanValue*1E6,
    Value.Unit == "µg/100mL" ~ Value.MeanValue/100,
    Value.Unit == "mg/100cm³" ~ Value.MeanValue*10,
    Value.Unit == "µg/5mL" ~ Value.MeanValue/0.2,
    Value.Unit == "mg/200mL" ~ Value.MeanValue*5,
    Value.Unit %in% c("mol/L", "M", "mol","mol/dm³") ~ (Value.MeanValue*MW.g.mol)*1E3,
    Value.Unit %in% c("mmol/L", "mM", "mmol/dm³", "mol/m³") ~ (Value.MeanValue*MW.g.mol),
    Value.Unit %in% c("µmol/L", "µM", "mmol","µm", "µmol/dm³", "uM/L", "µM/L", "mmol/m³", "nmol/mL") ~ (Value.MeanValue*MW.g.mol)/1E3,
    Value.Unit %in% c("nmol/L", "nmol", "nM/L", "nM")~ (Value.MeanValue*MW.g.mol)/1E6,
    Value.Unit == c("pM")~ (Value.MeanValue*MW.g.mol)/1E9,
    TRUE ~ as.numeric(NA)
  ),
  # Making sure that all units that are convertable into mg/L are actually converted to the same unit
  # including values reported as molar units, where 1 M = 1 mol/L (https://en.wikipedia.org/wiki/Molar_concentration)
  Value.unit.mg_l = as.factor(case_when(
    Value.Unit %in% c(
      "µg/L", "µg/cm³","ng/L","ng/mL","ppm", "ppb", "pg/mL", "mg/mL", "g/L", "g/dm³", 
      "µM", "µm", "mM", "nM", "M", "pM", "mol", "nmol", "mmol",
      "mg/dm³", "g/m³", "µg/dm³", "µg/100mL", "µg/µL", "µg/5mL", "µg/10L", "mg/L",
      "µg/mm³", "pg/L", "g/mL", "mg/200mL", "mol/dm³", "µg/mL", "nmol/L", "nM/L", "mg/100cm³",
      "µmol/L", "µmol/dm³", "uM/L", "µM/L", "mmol/L", "mmol/dm³", 
      "mol/L", "mmol/m³", "µg/3.5L", "mol/m³", "nmol/mL" ) ~ "mg/L",
      TRUE ~ as.character(NA)))
  )

```

### Filtering non-mg/L units

```{r dur_and_val_filtering, warning = FALSE}
# FILTER STEP! 
# Removing effect concentrations that was reported as NA or "0", as well as Value.mg_l == NA

HESTIA_HC20_DB_effect_conc_filter <- HESTIA_HC20_DB_unit_and_value_conv %>% 
  filter(
    # Removing records not convertible into mg/L due to inapplicable units 
    !is.na(Value.mg_l),
    # Removing records missing mol weights.
    !is.na(MW.g.mol), 
    # Removing effect concentration "0"
    Value.MeanValue != 0
  ) 

```

### Acute/chronic Definition

 Acute is considered when 
 ≤1 d for algae, cyanobacteria and microorganism, 
 ≤4 d for invertebrates (crustaceans), 
 ≤7d for fishes, invertebrates (noncrustaceans), vertebrates, and aquatic plants other than algae” [Aurisano et al., 2019, p. 2570]
 
 However, Müeller 2017 reports using different cut off times for Acute/Chronic definitions:
 ≤1 d for microorganisms; 
 ≤4 d for algae, cyanobacteria, and crustaceans; 
 ≤7 d for invertebrates, fishes, and aquatic plants other than algae
 
 I will apply the same as Aurisano (24h for microorganisms, algae and cyanobacteria).
```{r}
HESTIA_HC20_DB_val.unit_filter <- HESTIA_HC20_DB_effect_conc_filter %>% 
  mutate(Time.Hours = as.numeric(Time.Hours)) %>%
  # Defining time chronic/Acute exposure time units for USEtox classification
  mutate(AcuteChronic = as.factor(
    case_when(
      Taxonomy.Group %in% c("Fish", "Plant", "Insect", "Mollusca", "Annellidae", "Amphibian") ~ case_when(Time.Hours <= 168 ~ "Acute",
                                                                                                          Time.Hours > 168 ~ "Chronic"),
      Taxonomy.Group == "Crustacean" ~ case_when(Time.Hours <= 96 ~ "Acute",
                                    Time.Hours > 96 ~ "Chronic"),
      Taxonomy.Group %in% c("Algae", "Rotifera") ~ case_when(Time.Hours <= 24 ~ "Acute",
                                            Time.Hours > 24 ~ "Chronic"),
      Taxonomy.Group == "Others" & !Phylum %in% c("Chordata", "Arthropoda", "Cnidaria") ~ case_when(Time.Hours <= 24 ~ "Acute",
                             Time.Hours > 24 ~ "Chronic"),
      Taxonomy.Group == "Others" & Phylum == "Arthropoda" ~ case_when(Time.Hours <= 96 ~ "Acute",
                             Time.Hours > 96 ~ "Chronic"),
                             TRUE ~ case_when(Time.Hours <= 168 ~ "Acute",
                                              Time.Hours > 168 ~ "Chronic") ) 
    ))

```

## Duration unit filter
This operation will remove all records with experiment durations that are missing or being below 24h.
```{r dur_unit_filter }
HESTIA_HC20_DB_time.unit_filter <- HESTIA_HC20_DB_val.unit_filter %>% 
  mutate(Time.Hours = as.numeric(Time.Hours)) %>% 
  filter(Time.Hours != 0,
         Time.Hours >= 24, 
         !is.na(Time.Hours))
```


## Step 5. Endpoint EC0eq conversion function 
EC10eq conversion factors from Table 3 [Aurisano et al., 2019] (Species-group specific conversions) are available
Conversions for endpoints into EC10eq
To EC10eq-chronic from EC50chronic	
 - Fish	1.55 (0.67–3.66)
 - Invertebrates	1.94 (1.56–2.41)
 - Algae and bacteria	2.24 (1.90–2.65)
To EC10eq-chronic from NOECchronic	
 - Invertebrates	0.95 (0.77–1.16)
 - Algae and bacteria	0.44 (0.39–0.49)
To EC10eq-chronic from EC50acute	
 - Fish	7.44 (2.92–18.95)
 - Invertebrates	3.38 (2.14–5.34)
To EC10eq-chronic from NOECacute	
 - Fish	3.97 (0.90–17.39)
 - Invertebrates	1.55 (0.91–2.64)
When Species-groups fall outside of the specified conversions in Table 3 [Aurisano et al., 2019]
I will apply generalized conversions from Table 4:
To EC10eq-chronic from EC50chronic =
 - 2 (1.8–2.5)
To EC10eq-chronic from NOECchronic = 	
 - 0.6 (0.4–0.7)
To EC10eq-chronic from EC50acute =
 - 4 (2.6–6.1) 
To EC10eq-chronic from NOECacute = 
 - 1.8 (1.0–2.7)
 Additionally, when extrapolation factors have been added, I add columns defining the CI for the respective conversion factor (Also defined in Aurisano et al., 2019) 

The following operation relies on functions found in `ec10eq_extrapolation_function` alongside the argument `mapply` to perform conversions rowwise across the entire df.
This operation takes a couple of minutes.
```{r EC10eq_conversions}
# load EC10eq converson function
source("../code/EC10eq_conversion_functions.R")

system.time(Q_dat <- HESTIA_HC20_DB_time.unit_filter %>% 
  mutate(
    EC10eq = mapply(ec10eq_extrapolation_function, Value.mg_l, Endpoint, AcuteChronic, Taxonomy.Group, "extpl"),
    EC10eq_high = mapply(ec10eq_extrapolation_function, Value.mg_l, Endpoint, AcuteChronic, Taxonomy.Group, "high_CI"),
    EC10eq_low = mapply(ec10eq_extrapolation_function, Value.mg_l, Endpoint, AcuteChronic, Taxonomy.Group, "low_CI"),
    EC10eq_Acute = case_when(AcuteChronic == "Acute" ~ EC10eq, TRUE ~ as.numeric(NA)),
    EC10eq_Chronic = case_when(AcuteChronic == "Chronic" ~ EC10eq, TRUE ~ as.numeric(NA)),
         No.Extrapolations = as.numeric(case_when(Endpoint_conv == "EC10" ~ 0, TRUE ~ 1))#,# Making sure to annotate whether an effect value is extrapolated or not for downstream applications.
    # DB = "HESTIA",
    # version = "HESTIA 1.3"
    )  )

# write.csv(expf_df, "../data/excel_references/EC10_extrapolation_factor_summary_table.csv", row.names = F)

write.csv(Q_dat, "../results/HESTIA_EC10eq_DB.csv", row.names = F)


```

# Data Wrangling visualization
Using the package `networkD3` (https://CRAN.R-project.org/package=networkD3)
```{r, echo=FALSE}

nodes = data.frame("name" = c(
   paste("Input Data, n = ", nrow(HESTIA_HC20_DB), sep = ""), 
   paste("ECOTOX, n = ", nrow(HESTIA_HC20_DB %>% filter(Database == "ECOTOX")), sep = ""),
   paste("ECETOC, n = ", nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic ECETOC")), sep = ""),
   paste("Japan MoE, n = ", nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic Japan MoE")), sep = ""),
   paste("Aquatic Oasis, n = ",nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic OASIS")), sep = ""),
   paste("Food TOX Hazard EFSA, n = ", nrow(HESTIA_HC20_DB %>% filter(Database == "Food TOX Hazard EFSA")), sep = ""),
   paste("Validated, n = ", nrow(Q_dat), sep = ""), 
   paste("a) n = ", nrow(HESTIA_HC20_DB) - nrow(HESTIA_HC20_DB_qualifier_filter), sep = ""), 
   paste("b) n = ", nrow(HESTIA_HC20_DB_qualifier_filter) - nrow(HESTIA_HC20_DB_Control.Type_filter), sep = ""), 
   paste("c) n = ", nrow(HESTIA_HC20_DB_Control.Type_filter) - nrow(HESTIA_HC20_DB_water_filter), sep = ""), 
   paste("d) n = ", nrow(HESTIA_HC20_DB_water_filter) - nrow(HESTIA_HC20_DB_effect_crit_filter), sep = ""), 
   paste("e) n = ", nrow(HESTIA_HC20_DB_effect_crit_filter) - nrow(HESTIA_HC20_DB_taxonomy_filter), sep = ""), 
   paste("f) n = ", nrow(HESTIA_HC20_DB_unit_and_value_conv) - nrow(HESTIA_HC20_DB_effect_conc_filter), sep = ""), 
   paste("g) n = ", nrow(HESTIA_HC20_DB_val.unit_filter) - nrow(HESTIA_HC20_DB_time.unit_filter), sep = ""),
   paste("EC50-acute, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Acute")), sep = ""),
   paste("EC50-chronic, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Chronic")), sep = ""),
   paste("EC10-acute, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Acute")), sep = ""),
   paste("EC10-chronic, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Chronic")), sep = ""),
   paste("NOEC-acute, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Acute")), sep = ""),
   paste("NOEC-chronic, n = ", nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Chronic")), sep = ""),
   "EC10eq-chronic"),
   "Node_Group" = c("Toolbox", rep("DBs", 5), "Validated_data", rep("Filter1", 7),  rep(c("EndpointA", "EndpointC"), 3), rep("EC10eq",1))
               )

links = as.data.frame(matrix(
  c(
    1,0,nrow(HESTIA_HC20_DB %>% filter(Database == "ECOTOX")),
    2,0,nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic ECETOC")),
    3,0,nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic Japan MoE")),
    4,0,nrow(HESTIA_HC20_DB %>% filter(Database == "Aquatic OASIS")),
    5,0,nrow(HESTIA_HC20_DB %>% filter(Database == "Food TOX Hazard EFSA")),
    0,6,nrow(Q_dat), # Stuff kept from filter operations
    0,7,nrow(HESTIA_HC20_DB) - nrow(HESTIA_HC20_DB_qualifier_filter), # Selecting effect data within a range 
    0,8,nrow(HESTIA_HC20_DB_qualifier_filter) - nrow(HESTIA_HC20_DB_Control.Type_filter),  # Test.Control == "insufficient" or "unsatisfactory"
    0,9,nrow(HESTIA_HC20_DB_Control.Type_filter) - nrow(HESTIA_HC20_DB_water_filter), # Non-FW media type
    0,10,nrow(HESTIA_HC20_DB_water_filter) - nrow(HESTIA_HC20_DB_effect_crit_filter), # Irrelevant effect criterions
    0,11,nrow(HESTIA_HC20_DB_effect_crit_filter) - nrow(HESTIA_HC20_DB_taxonomy_filter), # Taxonomy
    0,12,nrow(HESTIA_HC20_DB_unit_and_value_conv) - nrow(HESTIA_HC20_DB_effect_conc_filter), # Effect Unit/Value "na" or "0"
    0,13,nrow(HESTIA_HC20_DB_val.unit_filter) - nrow(HESTIA_HC20_DB_time.unit_filter), # Incorrect time unit
    # How many EC50 do we have? 
    6,14,nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Acute")),
    # How many LOEC do we have? 
    6,15,nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Chronic")),
    # How many NOEC do we have? 
    6,16,nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Acute")),
    # How many EC50 do we have? 
    6,17,nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Chronic")),
    # How many LOEC do we have? 
    6,18,nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Acute")),
    # How many NOEC do we have? 
    6,19,nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Chronic")),
    # How many Acute EC50 do we have? 
    14,20,nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Acute")),
    # How many Chronic EC50 do we have? 
    15,20,nrow(Q_dat %>% filter(Endpoint_conv == "EC50", AcuteChronic == "Chronic")),
    # How many Acute EC10 do we have? 
    16,20,nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Acute")),
    # How many Chronic do we have? 
    17,20,nrow(Q_dat %>% filter(Endpoint_conv == "EC10", AcuteChronic == "Chronic")),
    # How many Acute NOEC do we have? 
    18,20,nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Acute")),
    # How many Chronic NOEC do we have? 
    19,20,nrow(Q_dat %>% filter(Endpoint_conv == "NOEC", AcuteChronic == "Chronic"))
  ),
  byrow = TRUE, ncol = 3))

names(links) = c("source", "target", "value")
links$groups = c(rep("A", 5), "B", rep("C", 7), rep("D", 6), "A_EC10", "C_EC10","A_EC10", "C_EC10","A_EC10", "C_EC10")

Wrangle_plot <- sankeyNetwork(
  Links = links, Nodes = nodes,
  Source = "source", Target = "target",
  Value = "value", NodeID = "name", 
  LinkGroup = "groups", NodeGroup = "Node_Group",
  units = "n", fontFamily = "sans-serif",
  fontSize = 15, nodeWidth = 20, sinksRight = FALSE)

Wrangle_plot <- htmlwidgets::onRender(Wrangle_plot, '
  function(el) { 
    var cols_x = this.sankey.nodes().map(d => d.x).filter((v, i, a) => a.indexOf(v) === i).sort(function(a, b){return a - b});
    var labels = ["OECD Toolbox query", "Raw data input", "Data curation", "Acute/Chronic definitions", "EC10eq-conversion"];
    cols_x.forEach((d, i) => {
      d3.select(el).select("svg")
        .append("text")
        .attr("x", d)
        .attr("y", 12)
        .attr("font-family", "sans-serif")
        .text(labels[i]);
    })
  }
')


Wrangle_plot

saveNetwork(Wrangle_plot, "../figures/Wrangle_plot.html", selfcontained = TRUE)
saveWidget(Wrangle_plot, file = "Wrangle_plot_widget.html", selfcontained = TRUE, title = "Overview of data curation steps")


webshot::webshot(url= "../figures/Wrangle_plot.html", file = "../figures/Wrangle_plot.pdf", vwidth = 992, vheight = 744)
```

```{r}
# Specifying which columns i want to keep in the main dataset
common_name_elements <- c(
  "CAS.Number", "Database", "Species", "Genus", 
  "Taxonomy.Group", "Medium", "Effect", "Value.mg_l", "AcuteChronic", 
  "Endpoint", "Endpoint_conv", "Time.Hours",
  "EC10eq", "EC10eq_Chronic", "EC10eq_Acute", "No.Extrapolations", "Source")

# Adjusting the content of the HESTIA database
HESTIA_BASE_dat <- read.csv("../results/HESTIA_EC10eq_DB.csv") %>% 
  rename(Medium = Media.type) %>% 
  unite(Source, c("Title", "Author", "Year", "Reference.source", "URL", "DOI"), sep = ";", na.rm = TRUE) %>% 
  select(common_name_elements)

write.csv(HESTIA_BASE_dat, "../results/FINAL_HESTIA.csv", row.names = F)
write.csv(HESTIA_BASE_dat, "../HESTIA_Shiny/data/FINAL_HESTIA.csv", row.names = F)

```

## Calculating HC50_EC50 for the HESTIA_envirotox Database for backwards compatibility with previous LCA-tox versions.
Dependency on `../code/HC50_calculation_function.R`-file with the defined function. 
This operation requires Physchem/subst.use-group data to be joined with the toxicological data.
```{r HC50EC50}
source("../code/HC50_calculation_function.R")

# Attaching Physchem data to HESTIA dataset and outputting a df with HC50 data
HESTIA_HC50_calc <- HC50_calc_function(HESTIA_BASE_dat %>% left_join(x = ., y = NEW_PHYSCHEM, by = "CAS.Number"))
```

## HC20EC10eq calculations for HESTIA_BASE_dat

```{r HC20Calculations}
source("../code/HC20_calculation_function.R")

HESTIA_HC20_dataset <- HCx_calculator(HESTIA_BASE_dat, HCx = 20)

write.csv(HESTIA_HC20_dataset, "../results/HESTIA_HC20_dataset.csv", row.names = F)
```

## Running the weighted uncertainty model
```{r nlsModel, warning=FALSE, message=FALSE}
# Dataset to analyze is object `HESTIA_BASE_dat`

# load the nls function
 source("../code/least_squares_fit_model_code.R")

 # Running the operation with the HESTIA toxicity data set, generating a tibble object
system.time(nls_output <- nls_across_all(dataset = HESTIA_BASE_dat, MC_n = 1e+05, rm_singles = "YES"))

# Select relevant data-output
nls_output_df <- nls_output[,c(1:20, 26:27)]

# Summarize the nls output
nls_output_df %>% 
  count(status)

# write summary to file
write.csv(nls_output_df %>% 
  count(status), 
"../results/nls_sum.csv", row.names = F)

# Convert the list-object into a dataframe, selecting non-list vectors
# nls_output_df <- as.data.frame(do.call(cbind, nls_output[,c(1:20, 26:27)])) %>%
#  mutate(across(c(2:19, 26:27), ~ as.numeric(.x)),
#         CAS.Number = as.factor(CAS.Number),
#         status = as.character(status))

write.csv(nls_output_df, "../results/nls_output_df.csv", row.names = F)
write.csv(nls_output_df, "../HESTIA_Shiny/data/nls_output_df.csv", row.names = F)

```

### Inspecting the nls outputs that were not able to start! 
# Running the operation with a subset for a chemical in the negatives, but changing the concentration from mg L-1 to ng L-1
```{r inspectingNLS, include=FALSE, eval=FALSE}
bad_nls_cas <- nls_output_df %>% filter(grepl("Fail", status),
                                        n_sigma >= 5 & n_taxa_sigma >= 3) %>% pull(CAS.Number)

# Inspecting the data where nls starting parameters are bad
test_set <- HESTIA_BASE_dat %>% filter(CAS.Number %in% bad_nls_cas) %>% 
  mutate(EC10eq = EC10eq*1e6)

nls_fail_output <- nls_across_all(dataset = test_set, MC_n = 1e+05, rm_singles = "YES")

# Select relevant data-output
nls_fail_output_df <- nls_fail_output[,c(1:20, 26:27)]

# Summarize the nls output
nls_fail_output_df %>% 
  count(status)
  
nls_output_df %>% 
  filter(CAS.Number %in% bad_nls_cas)
```


## Merging Physchem & Tox data
```{r FinalDataset}
HESTIA_cfs <- left_join(
    x = NEW_PHYSCHEM, 
    y = HESTIA_HC20_dataset,
    by = "CAS.Number") %>% 
# Selection for the SHINY-app
  select(c(
    CAS.Number, PesticideAI_name, CanonicalSMILES, 
    MW.g.mol, pKaChemClass, pKa.gain, pKa.loss, Kow_L.L, Koc_L.kg,
    kH25C_Pa.m3.mol, Vapor.Pressure_Pa, Sol_mg.L,
    KdegA, KdegW, KdegSd, KdegSl, HC20EC10eq, BAF_L.Kg, 
    # mean_EC10eq, Sd_EC10eq, HC20,
    # Molecular.formula, Predefined.substance.type, 
    Substance_type, Group 
    #Subgroup, Heavy.Metals, Halogenated, definition, 
    # n_data_recs, n_species, sum_extrapolations, n_Taxonomy.Group 
    )
  ) %>% 
  mutate(across(contains("Kdeg"), ~ formatC(., format = "e")),
         across(contains("Kdeg"), ~ na_if(., "NA")))

write.csv(HESTIA_cfs, "../HESTIA_Shiny/data/HESTIA_cfs.csv", row.names = F)

```

Creating an output file with the USEtox 2.1 database input structure 
Defining a data frame shaped like the USEtox-input database

```{r}
# Reading in the USEtox Organics database names, to be able to export an identical list of data for easier USEtox input
  # USEtox_input_names <- names(readxl::read_xlsx("../data/Impact assessment/USEtox_substance_data_organics.xlsx", sheet = "Substance data", skip = 1))

USEtox_input <- data.frame(
 ...1 = seq(1, nrow(HESTIA_cfs), 1),
CASRN = HESTIA_cfs$CAS.Number,
Name = HESTIA_cfs$PesticideAI_name,
PesticideTargetClass = HESTIA_cfs$Group,
PesticideChemClass = HESTIA_cfs$Substance_type,
MW = as.numeric(HESTIA_cfs$MW.g.mol),
pKaChemClass = HESTIA_cfs$pKaChemClass,
pKa.gain = HESTIA_cfs$pKa.gain,
pKa.loss = HESTIA_cfs$pKa.loss,
KOW = HESTIA_cfs$Kow_L.L,
Koc = HESTIA_cfs$Koc_L.kg,
KH25C = HESTIA_cfs$kH25C_Pa.m3.mol,
Pvap25 = HESTIA_cfs$Vapor.Pressure_Pa,
Sol25 = HESTIA_cfs$Sol_mg.L,
Kdoc = rep(NA, nrow(HESTIA_cfs)),
KpSS = rep(NA, nrow(HESTIA_cfs)),
KpSd = rep(NA, nrow(HESTIA_cfs)),
KpSl = rep(NA, nrow(HESTIA_cfs)),
kdegA = HESTIA_cfs$KdegA,
kdegW = HESTIA_cfs$KdegW,
kdegSd = HESTIA_cfs$KdegSd,
kdegSl = HESTIA_cfs$KdegSl,
kdissP = rep(NA, nrow(HESTIA_cfs)),
kdisswheat = rep(NA, nrow(HESTIA_cfs)),
kdissrice = rep(NA, nrow(HESTIA_cfs)),
kdisstomato = rep(NA, nrow(HESTIA_cfs)),
kdissapple = rep(NA, nrow(HESTIA_cfs)),
kdisslettuce = rep(NA, nrow(HESTIA_cfs)),
kdisspotato = rep(NA, nrow(HESTIA_cfs)),
avlogEC20 = HESTIA_cfs$HC20EC10eq,
ED50inhnoncanc = rep(NA, nrow(HESTIA_cfs)),
ED50ingnoncanc = rep(NA, nrow(HESTIA_cfs)),
ED50inhcanc = rep(NA, nrow(HESTIA_cfs)),
ED50ingcanc = rep(NA, nrow(HESTIA_cfs)),
BAFroot = rep(NA, nrow(HESTIA_cfs)),
BAFleaf = rep(NA, nrow(HESTIA_cfs)),
BTFmeat = rep(NA, nrow(HESTIA_cfs)),
BTFmilk = rep(NA, nrow(HESTIA_cfs)),
BAFfish = HESTIA_cfs$BAF_L.Kg,
Flagged.Interim.Characterization.factor = rep(NA, nrow(HESTIA_cfs)),
...41 = rep(NA, nrow(HESTIA_cfs)),
...42 = rep(NA, nrow(HESTIA_cfs)),
...43 = rep(NA, nrow(HESTIA_cfs)),
...44 = rep(NA, nrow(HESTIA_cfs)),
...45 = rep(NA, nrow(HESTIA_cfs)),
...46 = rep(NA, nrow(HESTIA_cfs)),
...47 = rep(NA, nrow(HESTIA_cfs)),
...48 = rep(NA, nrow(HESTIA_cfs)),
...49 = rep(NA, nrow(HESTIA_cfs)),
USEtox.internal.identification.number = rep(NA, nrow(HESTIA_cfs))
)

write.csv(USEtox_input, "../results/HESTIA_HC20_USEtox_format.csv", row.names = F)

```

# Create one comprehensive supplementary .xlsx file with data to publish
```{r}
Supp <- openxlsx::createWorkbook(creator = "Oskar Nyberg")
openxlsx::addWorksheet(Supp, sheetName = "HESTIA_INVENTORY")
openxlsx::addWorksheet(Supp, sheetName = "PHYSCHEM")
openxlsx::addWorksheet(Supp, sheetName = "CAS_SMILES_MATCHING")
openxlsx::addWorksheet(Supp, sheetName = "TAXONOMIC_INFORMATION")
openxlsx::addWorksheet(Supp, sheetName = "CHEMICAL_PROPERTIES")
openxlsx::addWorksheet(Supp, sheetName = "USEtox_FORMAT")
openxlsx::addWorksheet(Supp, sheetName = "NLS_RESULTS")
openxlsx::addWorksheet(Supp, sheetName = "FULL_DATABASE")

# HESTIA chemical inventory "PesticideAI.csv"
openxlsx::writeData(Supp, sheet = "HESTIA_INVENTORY", x = read.csv("../data/excel_references/pesticideAI.csv")[, c(1,3:9)], startCol = 1, startRow = 1, colNames = T, rowNames = F)
# PHYSCHEM info
openxlsx::writeData(Supp, sheet = "PHYSCHEM", x = Physchem_HESTIA, startCol = 1, startRow = 1, colNames = T, rowNames = F)
# CAS SMILES matching
openxlsx::writeData(Supp, sheet = "CAS_SMILES_MATCHING", x = CAS_SMILES_list, startCol = 1, startRow = 1, colNames = T, rowNames = F)
# Taxonomic information
openxlsx::writeData(Supp, sheet = "TAXONOMIC_INFORMATION", x = read.csv("../data/Taxonomy/Species_taxonomy.csv"), startCol = 1, startRow = 1, colNames = T, rowNames = F)
# Chemical properties
openxlsx::writeData(Supp, sheet = "CHEMICAL_PROPERTIES", x = HESTIA_chem_prop_list_full, startCol = 1, startRow = 1, colNames = T, rowNames = F)
# USEtox_formatted database
openxlsx::writeData(Supp, sheet = "USEtox_FORMAT", x = USEtox_input, startCol = 1, startRow = 1, colNames = T, rowNames = F)
# NLS_dataset
openxlsx::writeData(Supp, sheet = "NLS_RESULTS", x = nls_output_df, startCol = 1, startRow = 1, colNames = T, rowNames = F)
# Final Database
openxlsx::writeData(Supp, sheet = "FULL_DATABASE", x = HESTIA_BASE_dat %>% select(-c(Genus, EC10eq_Chronic, EC10eq_Acute)), startCol = 1, startRow = 1, colNames = T, rowNames = F)

saveWorkbook(Supp, file = "../results/supplementary_data.xlsx", overwrite = TRUE)
gc()

```


